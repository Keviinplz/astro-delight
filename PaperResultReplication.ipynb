{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción\n",
    "\n",
    "En el presente notebook, buscaremos reproducir los resultados obtenidos en el paper de [DELIGHT](https://arxiv.org/pdf/2208.04310).\n",
    "\n",
    "Para esto, trabajaremos adaptando el modelo propuesto a PyTorch, y mediremos su rendimiento bajo las métricas propuestas por el paper.\n",
    "\n",
    "# Métricas\n",
    "\n",
    "Evaluaremos el desempeño de la red mediante 6 métricas sobre el conjunto de test\n",
    "\n",
    "- $$ RMSE = \\sqrt{MSE} = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} (Y_i - \\hat{Y_i})^2} $$\n",
    "- $$ Mean Deviaton = \\frac{1}{N} \\sum_{i=1}^{N} \\lVert Y_i - \\hat{Y_i} \\rVert $$\n",
    "- $$ Median Deviaton = mediana(\\lVert Y_i - \\hat{Y_i} \\rVert) $$\n",
    "- $$ Mode Deviaton = moda(\\lVert Y_i - \\hat{Y_i} \\rVert) $$\n",
    "\n",
    "Donde:\n",
    "- $N$: Es el tamaño total de los datos del conjunto de test.\n",
    "- $Y_i$: Es un vector 2d que representa la posición real de la galaxia host. $Y_i = (x_i, y_i)$\n",
    "- $\\hat{Y_i }$: Es un vector 2d que representa la posición predicha de la galaxia host. $\\hat{Y_i} = (\\hat{x_i}, \\hat{y_i})$\n",
    "\n",
    "# Baseline\n",
    "\n",
    "Los valores obtenidos para cada métrica en el paper son:\n",
    "- RMSE: 1.836 ± 0.05100\n",
    "- Mean Deviation: 0.783 ± 0.00900\n",
    "- Median Deviation: 0.468 ± 0.00800\n",
    "- Mode Deviation: 0.427 ± 0.05100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext tensorboard\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from typing import Callable\n",
    "from sklearn.utils import resample  # type: ignore\n",
    "\n",
    "StatisticFunction = Callable[[npt.NDArray[np.float32]], float]\n",
    "\n",
    "\n",
    "def bootstrap_statistic(\n",
    "    data: npt.NDArray[np.float32],\n",
    "    statistic: StatisticFunction,\n",
    "    n_iterations: int = 1000,\n",
    ") -> float:\n",
    "    stats = np.zeros(n_iterations)\n",
    "    for i in range(n_iterations):\n",
    "        sample: npt.NDArray[np.float32] = resample(data)  # type: ignore\n",
    "        stats[i] = statistic(sample)\n",
    "    return np.std(stats).item()\n",
    "\n",
    "\n",
    "def __assert_expected_shape(\n",
    "    y_true: npt.NDArray[np.float32], y_pred: npt.NDArray[np.float32]\n",
    ") -> None:\n",
    "    has_shape_2 = len(y_true.shape) == len(y_pred.shape) == 2\n",
    "    are_points = y_true.shape[1] == y_pred.shape[1] == 2\n",
    "    assert (\n",
    "        has_shape_2 and are_points\n",
    "    ), f\"Expected vectors of dim (N, 2): y_true={y_true.shape} y_pred={y_pred.shape}\"\n",
    "\n",
    "\n",
    "def rmse(\n",
    "    y_true: npt.NDArray[np.float32], y_pred: npt.NDArray[np.float32], pixscale: float\n",
    ") -> tuple[float, float]:\n",
    "    __assert_expected_shape(y_true, y_pred)\n",
    "\n",
    "    sum_distance_squared: npt.NDArray[np.float32] = np.sum(\n",
    "        (y_true - y_pred) ** 2, axis=1\n",
    "    )\n",
    "\n",
    "    value = np.sqrt(np.mean(sum_distance_squared)) * pixscale  # type: ignore\n",
    "    assert isinstance(value, float), f\"Expected float result: {value}\"\n",
    "    return value, bootstrap_statistic(\n",
    "        sum_distance_squared, lambda x: np.sqrt(np.mean(x)) * pixscale\n",
    "    )\n",
    "\n",
    "\n",
    "def mean_deviation(\n",
    "    y_true: npt.NDArray[np.float32], y_pred: npt.NDArray[np.float32], pixscale: float\n",
    ") -> tuple[float, float]:\n",
    "    __assert_expected_shape(y_true, y_pred)\n",
    "\n",
    "    deviation: npt.NDArray[np.float32] = np.linalg.norm(y_true - y_pred, axis=1)  # type: ignore\n",
    "    return np.mean(deviation).item() * pixscale, bootstrap_statistic(\n",
    "        deviation,\n",
    "        lambda x: np.mean(x) * pixscale,  # type: ignore\n",
    "    )\n",
    "\n",
    "\n",
    "def median_deviation(\n",
    "    y_true: npt.NDArray[np.float32], y_pred: npt.NDArray[np.float32], pixscale: float\n",
    ") -> tuple[float, float]:\n",
    "    __assert_expected_shape(y_true, y_pred)\n",
    "\n",
    "    deviation: npt.NDArray[np.float32] = np.linalg.norm(y_true - y_pred, axis=1)  # type: ignore\n",
    "    return np.median(deviation).item() * pixscale, bootstrap_statistic(\n",
    "        deviation,\n",
    "        lambda x: np.median(x) * pixscale,  # type: ignore\n",
    "    )\n",
    "\n",
    "\n",
    "def __get_mode_use_numpy(deviation: npt.NDArray[np.float32]) -> float:\n",
    "    counts, bin_edges = np.histogram(deviation, bins=np.linspace(0, 10, 200))\n",
    "    mode_bin_index = np.argmax(counts)\n",
    "    mode = (bin_edges[mode_bin_index] + bin_edges[mode_bin_index + 1]) / 2\n",
    "\n",
    "    return mode\n",
    "\n",
    "\n",
    "def mode_deviation(\n",
    "    y_true: npt.NDArray[np.float32], y_pred: npt.NDArray[np.float32], pixscale: float\n",
    ") -> tuple[float, float]:\n",
    "    __assert_expected_shape(y_true, y_pred)\n",
    "\n",
    "    deviation: npt.NDArray[np.float32] = (\n",
    "        np.linalg.norm(y_true - y_pred, axis=1) * pixscale\n",
    "    )  # type: ignore\n",
    "    mode = __get_mode_use_numpy(deviation)\n",
    "\n",
    "    return mode, bootstrap_statistic(\n",
    "        deviation,\n",
    "        __get_mode_use_numpy,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import OrderedDict\n",
    "from typing import TypedDict\n",
    "from functools import reduce\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "class DelightCnnParameters(TypedDict):\n",
    "    nconv1: int\n",
    "    nconv2: int\n",
    "    nconv3: int\n",
    "    ndense: int\n",
    "    levels: int\n",
    "    dropout: float\n",
    "    rot: bool\n",
    "    flip: bool\n",
    "\n",
    "\n",
    "class RotationAndFlipLayer(torch.nn.Module):\n",
    "    def __init__(self, rot: bool = True, flip: bool = True):\n",
    "        super().__init__()  # type: ignore\n",
    "        self.rot = rot\n",
    "        self.flip = flip\n",
    "        self.n_transforms = (int(flip) + 1) * (3 * int(rot) + 1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        stacked = reduce(lambda x, y: x * y, x.shape[:-3], 1)\n",
    "\n",
    "        if self.rot is False and self.flip is False:\n",
    "            x = x.reshape(stacked, x.shape[-3], x.shape[-2], x.shape[-1])\n",
    "            return x\n",
    "\n",
    "        w_dim = len(x.shape) - 2\n",
    "        h_dim = len(x.shape) - 1\n",
    "        transforms: tuple[torch.Tensor, ...]\n",
    "\n",
    "        if self.rot is False:\n",
    "            flipped = x.flip(dims=(h_dim,))\n",
    "            transforms = (x, flipped)\n",
    "\n",
    "        elif self.flip is False:\n",
    "            rot90 = x.rot90(k=1, dims=(w_dim, h_dim))\n",
    "            rot180 = x.rot90(k=2, dims=(w_dim, h_dim))\n",
    "            rot270 = x.rot90(k=3, dims=(w_dim, h_dim))\n",
    "            transforms = (x, rot90, rot180, rot270)\n",
    "\n",
    "        else:\n",
    "            rot90 = x.rot90(k=1, dims=(w_dim, h_dim))\n",
    "            rot180 = x.rot90(k=2, dims=(w_dim, h_dim))\n",
    "            rot270 = x.rot90(k=3, dims=(w_dim, h_dim))\n",
    "            flipped = x.flip(dims=(h_dim,))\n",
    "            flipped_rot90 = flipped.rot90(k=1, dims=(w_dim, h_dim))\n",
    "            flipped_rot180 = flipped.rot90(k=2, dims=(w_dim, h_dim))\n",
    "            flipped_rot270 = flipped.rot90(k=3, dims=(w_dim, h_dim))\n",
    "            transforms = (\n",
    "                x,\n",
    "                rot90,\n",
    "                rot180,\n",
    "                rot270,\n",
    "                flipped,\n",
    "                flipped_rot90,\n",
    "                flipped_rot180,\n",
    "                flipped_rot270,\n",
    "            )\n",
    "\n",
    "        x = torch.cat(transforms, dim=1)\n",
    "        return x.reshape(\n",
    "            stacked * self.n_transforms, x.shape[-3], x.shape[-2], x.shape[-1]\n",
    "        )\n",
    "\n",
    "\n",
    "class DelightCnn(torch.nn.Module):\n",
    "    def __init__(self, options: DelightCnnParameters, channels: int = 1):\n",
    "        super().__init__()  # type: ignore\n",
    "        bottleneck: OrderedDict[str, torch.nn.Module] = OrderedDict(\n",
    "            [\n",
    "                (\"conv1\", torch.nn.Conv2d(channels, options[\"nconv1\"], 3)),\n",
    "                (\"relu1\", torch.nn.ReLU()),\n",
    "                (\"mp1\", torch.nn.MaxPool2d(2)),\n",
    "                (\"conv2\", torch.nn.Conv2d(options[\"nconv1\"], options[\"nconv2\"], 3)),\n",
    "                (\"relu2\", torch.nn.ReLU()),\n",
    "                (\"mp2\", torch.nn.MaxPool2d(2)),\n",
    "                (\"conv3\", torch.nn.Conv2d(options[\"nconv2\"], options[\"nconv3\"], 3)),\n",
    "                (\"relu3\", torch.nn.ReLU()),\n",
    "                (\"flatten\", torch.nn.Flatten()),\n",
    "            ]\n",
    "        )\n",
    "        linear_in = self._compute_dense_features(\n",
    "            levels=options[\"levels\"], bottleneck=bottleneck\n",
    "        )\n",
    "        self.fc1 = torch.nn.Linear(\n",
    "            in_features=linear_in, out_features=options[\"ndense\"]\n",
    "        )\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "        self.dropout = torch.nn.Dropout(p=options[\"dropout\"])\n",
    "        self.fc2 = torch.nn.Linear(in_features=options[\"ndense\"], out_features=2)\n",
    "        self.rot_and_flip = RotationAndFlipLayer(\n",
    "            rot=options[\"rot\"], flip=options[\"flip\"]\n",
    "        )\n",
    "        self.bottleneck = torch.nn.Sequential(bottleneck)\n",
    "\n",
    "    def _compute_dense_features(\n",
    "        self,\n",
    "        *,\n",
    "        bottleneck: OrderedDict[str, torch.nn.Module],\n",
    "        levels: int,\n",
    "    ) -> int:\n",
    "        w = 30\n",
    "        h = 30\n",
    "        conv_out = 0\n",
    "        for layer in bottleneck.values():\n",
    "            k: int\n",
    "            if isinstance(layer, torch.nn.Conv2d):\n",
    "                k = layer.kernel_size[0]\n",
    "                w = w - k + 1\n",
    "                h = h - k + 1\n",
    "                conv_out = layer.out_channels\n",
    "            if isinstance(layer, torch.nn.MaxPool2d):\n",
    "                k = layer.kernel_size  # type: ignore\n",
    "                w = math.floor((w - k) / 2 + 1)\n",
    "                h = math.floor((h - k) / 2 + 1)\n",
    "\n",
    "        return w * h * conv_out * levels\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        batch = x.shape[0]  # TODO: Remove batch dependency\n",
    "\n",
    "        # Apply flips and rotations over level (L) dimension\n",
    "        x = self.rot_and_flip(x)\n",
    "\n",
    "        # Bottleneck\n",
    "        x = self.bottleneck(x)\n",
    "\n",
    "        # Undo transformations\n",
    "        x = x.reshape(batch, self.rot_and_flip.n_transforms, -1)\n",
    "\n",
    "        # Linear\n",
    "        x = self.fc1(x)\n",
    "        x = self.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x.reshape(batch, self.rot_and_flip.n_transforms * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-19 05:43:29.395900: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-19 05:43:29.395944: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-19 05:43:29.395972: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-19 05:43:29.405589: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "from typing import Any, cast\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.experimental.numpy as tnp  # type: ignore\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class DelightDatasetType(Enum):\n",
    "    TRAIN = \"TRAIN\"\n",
    "    TEST = \"TEST\"\n",
    "    VALIDATION = \"VALIDATION\"\n",
    "    P_TRAIN = \"PRODUCTION_TRAIN\"\n",
    "    P_VAL = \"PRODUCTION_VALIDATION\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DelightDatasetOptions:\n",
    "    source: str\n",
    "    n_levels: int\n",
    "    fold: int\n",
    "    mask: bool\n",
    "    object: bool\n",
    "    rot: bool\n",
    "    flip: bool\n",
    "    balance: bool = True\n",
    "\n",
    "\n",
    "class DelightDataset(Dataset[tuple[torch.Tensor, torch.Tensor]]):\n",
    "    def __init__(\n",
    "        self,\n",
    "        options: DelightDatasetOptions,\n",
    "        datatype: DelightDatasetType,\n",
    "        transform_y: bool = True,\n",
    "    ):\n",
    "        X, y = self.get_data(options, datatype)\n",
    "\n",
    "        self.X = torch.Tensor(X).permute(0, 3, 1, 2)\n",
    "\n",
    "        self.y = (\n",
    "            self.transform(\n",
    "                y,\n",
    "                options.rot,\n",
    "                options.flip,\n",
    "            )\n",
    "            if transform_y\n",
    "            else torch.from_numpy(y)  # type: ignore\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def get_data(\n",
    "        cls, options: DelightDatasetOptions, datatype: DelightDatasetType\n",
    "    ) -> tuple[npt.NDArray[np.float32], npt.NDArray[np.float32]]:\n",
    "        enum = {\n",
    "            DelightDatasetType.TRAIN: cls.get_train_data,\n",
    "            DelightDatasetType.VALIDATION: cls.get_val_data,\n",
    "            DelightDatasetType.TEST: cls.get_test_data,\n",
    "            DelightDatasetType.P_TRAIN: cls.get_production_train_data,\n",
    "            DelightDatasetType.P_VAL: cls.get_production_val_data,\n",
    "        }\n",
    "\n",
    "        return enum[datatype](options)\n",
    "\n",
    "    @classmethod\n",
    "    def get_train_data(\n",
    "        cls, options: DelightDatasetOptions\n",
    "    ) -> tuple[npt.NDArray[np.float32], npt.NDArray[np.float32]]:\n",
    "        nlevels = options.n_levels\n",
    "        ifold = options.fold\n",
    "        domask = options.mask\n",
    "        doobject = options.object\n",
    "        source = options.source\n",
    "        balance = options.balance\n",
    "\n",
    "        oid_train: npt.NDArray[np.str_] = np.load(\n",
    "            os.path.join(\n",
    "                source,\n",
    "                f\"oid_train_nlevels{nlevels}_fold{ifold}_mask{domask}_objects{doobject}.npy\",\n",
    "            ),\n",
    "            allow_pickle=True,\n",
    "        )\n",
    "        y_train: npt.NDArray[np.float32] = np.load(\n",
    "            os.path.join(\n",
    "                source,\n",
    "                f\"y_train_nlevels{nlevels}_fold{ifold}_mask{domask}_objects{doobject}.npy\",\n",
    "            )\n",
    "        )\n",
    "        X_train: npt.NDArray[np.float32] = np.load(\n",
    "            os.path.join(\n",
    "                source,\n",
    "                f\"X_train_nlevels{nlevels}_fold{ifold}_mask{domask}_objects{doobject}.npy\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if balance is False:\n",
    "            return X_train, y_train\n",
    "\n",
    "        # create balanced training set\n",
    "        idxAsiago = np.array(\n",
    "            [i for i in range(oid_train.shape[0]) if oid_train[i][:2] == \"SN\"]\n",
    "        )\n",
    "        idxZTF = np.array(\n",
    "            [i for i in range(oid_train.shape[0]) if oid_train[i][:3] == \"ZTF\"]\n",
    "        )\n",
    "        nimb = int(idxZTF.shape[0] / idxAsiago.shape[0])\n",
    "\n",
    "        idxbal = np.array([], dtype=int)\n",
    "        for i in range(nimb + 1):\n",
    "            idxbal = np.concatenate([idxbal, idxAsiago])\n",
    "            idxbal = np.concatenate(\n",
    "                [\n",
    "                    idxbal,\n",
    "                    idxZTF[\n",
    "                        i * idxAsiago.shape[0] : min(\n",
    "                            idxZTF.shape[0], (i + 1) * idxAsiago.shape[0]\n",
    "                        )\n",
    "                    ],\n",
    "                ]\n",
    "            )\n",
    "        # shuffle inplace\n",
    "        np.random.shuffle(idxbal)\n",
    "\n",
    "        oid_train = oid_train[idxbal]\n",
    "        X_train = X_train[idxbal]\n",
    "        y_train = y_train[idxbal]\n",
    "\n",
    "        return X_train, y_train\n",
    "\n",
    "    @classmethod\n",
    "    def get_val_data(\n",
    "        cls, options: DelightDatasetOptions\n",
    "    ) -> tuple[npt.NDArray[np.float32], npt.NDArray[np.float32]]:\n",
    "        nlevels = options.n_levels\n",
    "        ifold = options.fold\n",
    "        domask = options.mask\n",
    "        doobject = options.object\n",
    "        source = options.source\n",
    "        pixscale = 0.25\n",
    "\n",
    "        oid_val: npt.NDArray[np.str_] = np.load(\n",
    "            os.path.join(\n",
    "                source,\n",
    "                f\"oid_val_nlevels{nlevels}_fold{ifold}_mask{domask}_objects{doobject}.npy\",\n",
    "            ),\n",
    "            allow_pickle=True,\n",
    "        )\n",
    "        y_val: npt.NDArray[np.float32] = np.load(\n",
    "            os.path.join(\n",
    "                source,\n",
    "                f\"y_val_nlevels{nlevels}_fold{ifold}_mask{domask}_objects{doobject}.npy\",\n",
    "            )\n",
    "        )\n",
    "        X_val: npt.NDArray[np.float32] = np.load(\n",
    "            os.path.join(\n",
    "                source,\n",
    "                f\"X_val_nlevels{nlevels}_fold{ifold}_mask{domask}_objects{doobject}.npy\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # mask only the validation set (having difficult cases in the training set helps the validation)\n",
    "        distance = np.sqrt(np.sum(y_val**2, axis=1))\n",
    "        mask = (distance * pixscale) < 60\n",
    "        X_val = X_val[mask]\n",
    "        y_val = y_val[mask]\n",
    "        oid_val = oid_val[mask]\n",
    "\n",
    "        return X_val, y_val\n",
    "\n",
    "    @classmethod\n",
    "    def get_test_data(\n",
    "        cls, options: DelightDatasetOptions\n",
    "    ) -> tuple[npt.NDArray[np.float32], npt.NDArray[np.float32]]:\n",
    "        nlevels = options.n_levels\n",
    "        domask = options.mask\n",
    "        doobject = options.object\n",
    "        source = options.source\n",
    "\n",
    "        # oid_test = np.load(os.path.join(source, f\"oid_test_nlevels{nlevels}_mask{domask}_objects{doobject}.npy\"), allow_pickle=True)\n",
    "        y_test = np.load(\n",
    "            os.path.join(\n",
    "                source, f\"y_test_nlevels{nlevels}_mask{domask}_objects{doobject}.npy\"\n",
    "            )\n",
    "        )\n",
    "        X_test = np.load(\n",
    "            os.path.join(\n",
    "                source, f\"X_test_nlevels{nlevels}_mask{domask}_objects{doobject}.npy\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return X_test, y_test\n",
    "\n",
    "    @classmethod\n",
    "    def get_production_train_data(\n",
    "        cls, options: DelightDatasetOptions\n",
    "    ) -> tuple[npt.NDArray[np.float32], npt.NDArray[np.float32]]:\n",
    "        source = options.source\n",
    "        nlevels = options.n_levels\n",
    "        ifold = options.fold\n",
    "        domask = options.mask\n",
    "        doobject = options.object\n",
    "\n",
    "        y_train = np.load(\n",
    "            os.path.join(\n",
    "                source,\n",
    "                f\"y_train_nlevels{nlevels}_fold{ifold}_mask{domask}_objects{doobject}.npy\",\n",
    "            )\n",
    "        )\n",
    "        X_train = np.load(\n",
    "            os.path.join(\n",
    "                source,\n",
    "                f\"X_train_nlevels{nlevels}_fold{ifold}_mask{domask}_objects{doobject}.npy\",\n",
    "            )\n",
    "        )\n",
    "        y_val = np.load(\n",
    "            os.path.join(\n",
    "                source,\n",
    "                f\"y_val_nlevels{nlevels}_fold{ifold}_mask{domask}_objects{doobject}.npy\",\n",
    "            )\n",
    "        )\n",
    "        X_val = np.load(\n",
    "            os.path.join(\n",
    "                source,\n",
    "                f\"X_val_nlevels{nlevels}_fold{ifold}_mask{domask}_objects{doobject}.npy\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "        X_train = np.concatenate([X_train, X_val])\n",
    "        y_train = np.concatenate([y_train, y_val])\n",
    "\n",
    "        return X_train, y_train\n",
    "\n",
    "    @classmethod\n",
    "    def get_production_val_data(\n",
    "        cls, options: DelightDatasetOptions\n",
    "    ) -> tuple[npt.NDArray[np.float32], npt.NDArray[np.float32]]:\n",
    "        return cls.get_test_data(options)\n",
    "\n",
    "    @staticmethod\n",
    "    def transform(\n",
    "        y: np.ndarray[Any, np.dtype[np.float32]], rot: bool, flip: bool\n",
    "    ) -> torch.Tensor:\n",
    "        transformed: tuple[np.ndarray[Any, np.dtype[np.float32]], ...]\n",
    "\n",
    "        if rot is False and flip is False:\n",
    "            return torch.Tensor(y)\n",
    "\n",
    "        yflip = cast(np.ndarray[Any, np.dtype[np.float32]], [1, -1] * y)\n",
    "        if rot is False:\n",
    "            transformed = (y, yflip)\n",
    "\n",
    "        y90 = cast(np.ndarray[Any, np.dtype[np.float32]], [-1, 1] * y[:, ::-1])\n",
    "        y180 = cast(np.ndarray[Any, np.dtype[np.float32]], [-1, 1] * y90[:, ::-1])\n",
    "        y270 = cast(np.ndarray[Any, np.dtype[np.float32]], [-1, 1] * y180[:, ::-1])\n",
    "        yflip90 = cast(np.ndarray[Any, np.dtype[np.float32]], [-1, 1] * yflip[:, ::-1])\n",
    "        yflip180 = cast(\n",
    "            np.ndarray[Any, np.dtype[np.float32]], [-1, 1] * yflip90[:, ::-1]\n",
    "        )\n",
    "        yflip270 = cast(\n",
    "            np.ndarray[Any, np.dtype[np.float32]], [-1, 1] * yflip180[:, ::-1]\n",
    "        )\n",
    "\n",
    "        if flip is False:\n",
    "            transformed = (y, y90, y180, y270)\n",
    "        else:\n",
    "            transformed = (y, y90, y180, y270, yflip, yflip90, yflip180, yflip270)\n",
    "\n",
    "        return torch.Tensor(np.concatenate(transformed, axis=1))\n",
    "\n",
    "    @staticmethod\n",
    "    def derotate(y_pred_numpy: npt.NDArray[np.float32]) -> npt.NDArray[np.float32]:\n",
    "        return (\n",
    "            np.dstack(\n",
    "                [\n",
    "                    y_pred_numpy.reshape((y_pred_numpy.shape[0], 8, 2))[:, 0],\n",
    "                    y_pred_numpy.reshape((y_pred_numpy.shape[0], 8, 2))[:, 1, ::-1]\n",
    "                    * [1, -1],\n",
    "                    y_pred_numpy.reshape((y_pred_numpy.shape[0], 8, 2))[:, 2, :]\n",
    "                    * [-1, -1],\n",
    "                    y_pred_numpy.reshape((y_pred_numpy.shape[0], 8, 2))[:, 3, ::-1]\n",
    "                    * [-1, 1],\n",
    "                    y_pred_numpy.reshape((y_pred_numpy.shape[0], 8, 2))[:, 4, :]\n",
    "                    * [1, -1],\n",
    "                    y_pred_numpy.reshape((y_pred_numpy.shape[0], 8, 2))[:, 5, ::-1],\n",
    "                    y_pred_numpy.reshape((y_pred_numpy.shape[0], 8, 2))[:, 6, :]\n",
    "                    * [-1, 1],\n",
    "                    y_pred_numpy.reshape((y_pred_numpy.shape[0], 8, 2))[:, 7, ::-1]\n",
    "                    * [-1, -1],\n",
    "                ]\n",
    "            )\n",
    "            .reshape((y_pred_numpy.shape[0], 2, 8))\n",
    "            .swapaxes(1, 2)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        x = self.X[idx]\n",
    "        y = self.y[idx]\n",
    "\n",
    "        if len(x.shape) == 3:  # has no channel information\n",
    "            levels, width, height = x.shape\n",
    "            x = x.reshape(levels, 1, width, height)  # asume 1 channel information\n",
    "        return x, y\n",
    "\n",
    "    def to_tf_dataset(self) -> tuple[tf.Tensor, tf.Tensor]:\n",
    "        X = cast(np.ndarray[Any, np.dtype[np.float32]], self.X.numpy())\n",
    "        y = cast(np.ndarray[Any, np.dtype[np.float32]], self.y.numpy())\n",
    "\n",
    "        return tnp.copy(X.transpose((0, 2, 3, 1))), tnp.copy(y)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-19 05:43:31,452\tWARNING __init__.py:21 -- Package pickle5 becomes unnecessary in Python 3.8 and above. Its presence may confuse libraries including Ray. Please uninstall the package.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tempfile\n",
    "from typing import TypedDict, Literal\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from ray import train\n",
    "from ray.train import Checkpoint\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "import logging\n",
    "\n",
    "\n",
    "class HyperParameters(TypedDict):\n",
    "    lr: float\n",
    "    batch_size: int | float\n",
    "    nconv1: int | float\n",
    "    nconv2: int | float\n",
    "    nconv3: int | float\n",
    "    ndense: int | float\n",
    "    dropout: float\n",
    "    epochs: int\n",
    "\n",
    "\n",
    "class EvaluationResult(TypedDict):\n",
    "    rmse: tuple[float, float]\n",
    "    mean_deviation: tuple[float, float]\n",
    "    median_deviation: tuple[float, float]\n",
    "    mode_deviation: tuple[float, float]\n",
    "\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience: int = 1, min_delta: float = 0.0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter: int = 0\n",
    "        self.min_validation_loss = float(\"inf\")\n",
    "\n",
    "    def early_stop(self, validation_loss: float, logger: logging.Logger) -> bool:\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            logger.info(\n",
    "                f\"Validation loss has been improved from {self.min_validation_loss} -> {validation_loss}\"\n",
    "            )\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            logger.info(\n",
    "                f\"Validation loss is not improving. Best val loss={self.min_validation_loss}\"\n",
    "            )\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "\n",
    "def _get_value_from_parameter(parameter: int | float, base: int = 2) -> int:\n",
    "    return int(base**parameter) if isinstance(parameter, float) else parameter\n",
    "\n",
    "\n",
    "def get_delight_cnn_parameters(\n",
    "    params: HyperParameters, options: DelightDatasetOptions\n",
    ") -> DelightCnnParameters:\n",
    "    return {\n",
    "        \"nconv1\": _get_value_from_parameter(params[\"nconv1\"]),\n",
    "        \"nconv2\": _get_value_from_parameter(params[\"nconv2\"]),\n",
    "        \"nconv3\": _get_value_from_parameter(params[\"nconv3\"]),\n",
    "        \"ndense\": _get_value_from_parameter(params[\"ndense\"]),\n",
    "        \"levels\": options.n_levels,\n",
    "        \"dropout\": params[\"dropout\"],\n",
    "        \"rot\": options.rot,\n",
    "        \"flip\": options.flip,\n",
    "    }\n",
    "\n",
    "\n",
    "def _train_one_epoch(\n",
    "    *,\n",
    "    device: str,\n",
    "    train_dl: DataLoader[tuple[torch.Tensor, torch.Tensor]],\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    model: DelightCnn,\n",
    "    criterion: torch.nn.MSELoss,\n",
    "    writer: SummaryWriter,\n",
    "    is_ray: bool,\n",
    "    epoch: int,\n",
    "):\n",
    "    running_loss = 0.0\n",
    "    inputs: torch.Tensor\n",
    "    positions: torch.Tensor\n",
    "    outputs: torch.Tensor\n",
    "    loss: torch.Tensor\n",
    "\n",
    "    model.train()\n",
    "    for i, (inputs, positions) in enumerate(train_dl):\n",
    "        inputs, positions = inputs.to(device), positions.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, positions)\n",
    "        loss.backward()  # type: ignore\n",
    "\n",
    "        optimizer.step()\n",
    "        loss_value = loss.item()\n",
    "\n",
    "        if is_ray is False:\n",
    "            t = epoch * len(train_dl) + i  # type: ignore\n",
    "            writer.add_scalar(\"[MSE Loss]: Train\", loss_value, t)  # type: ignore\n",
    "\n",
    "        running_loss += loss_value * inputs.size(0)\n",
    "\n",
    "    return running_loss / len(train_dl.dataset)  # type: ignore\n",
    "\n",
    "\n",
    "def _validate_train(\n",
    "    *,\n",
    "    device: str,\n",
    "    val_dl: DataLoader[tuple[torch.Tensor, torch.Tensor]],\n",
    "    model: DelightCnn,\n",
    "    criterion: torch.nn.MSELoss,\n",
    "):\n",
    "    running_loss = 0.0\n",
    "    data: tuple[torch.Tensor, torch.Tensor]\n",
    "    outputs: torch.Tensor\n",
    "    loss: torch.Tensor\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(val_dl):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "\n",
    "    return running_loss / len(val_dl.dataset)  # type: ignore\n",
    "\n",
    "\n",
    "def _train(\n",
    "    *,\n",
    "    start_epoch: int,\n",
    "    num_epochs: int,\n",
    "    device: str,\n",
    "    train_dl: DataLoader[tuple[torch.Tensor, torch.Tensor]],\n",
    "    val_dl: DataLoader[tuple[torch.Tensor, torch.Tensor]],\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    model: DelightCnn,\n",
    "    criterion: torch.nn.MSELoss,\n",
    "    logger: logging.Logger,\n",
    "    early_stop: bool,\n",
    "    is_ray: bool = False,\n",
    "):\n",
    "    model.to(device)\n",
    "    writer = SummaryWriter(\n",
    "        comment=datetime.datetime.now().strftime(\"%Y-%m-%dT%H-%M-%SZ\")\n",
    "    )\n",
    "    early_stopper = EarlyStopper(patience=3, min_delta=0)\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        train_loss = _train_one_epoch(\n",
    "            device=device,\n",
    "            train_dl=train_dl,\n",
    "            optimizer=optimizer,\n",
    "            model=model,\n",
    "            criterion=criterion,\n",
    "            is_ray=is_ray,\n",
    "            writer=writer,\n",
    "            epoch=epoch,\n",
    "        )\n",
    "\n",
    "        val_loss = _validate_train(\n",
    "            device=device, val_dl=val_dl, model=model, criterion=criterion\n",
    "        )\n",
    "\n",
    "        logger.info(\n",
    "            f\"[EPOCH {epoch+1}] train loss = {train_loss} | val_loss = {val_loss}\"\n",
    "        )\n",
    "        metrics = {\"val_loss\": val_loss, \"train_loss\": train_loss}\n",
    "\n",
    "        if is_ray is False:\n",
    "            writer.add_scalars(\"[MSE Loss]: Train / Validation\", metrics, epoch)  # type: ignore\n",
    "        else:\n",
    "            with tempfile.TemporaryDirectory() as tempdir:\n",
    "                torch.save(  # type: ignore\n",
    "                    {\n",
    "                        \"epoch\": epoch,\n",
    "                        \"net_state_dict\": model.state_dict(),\n",
    "                        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                    },\n",
    "                    os.path.join(tempdir, \"checkpoint.pt\"),\n",
    "                )\n",
    "                train.report(  # type: ignore\n",
    "                    metrics=metrics,\n",
    "                    checkpoint=Checkpoint.from_directory(tempdir),  # type: ignore\n",
    "                )\n",
    "\n",
    "        if early_stop and early_stopper.early_stop(\n",
    "            validation_loss=val_loss, logger=logger\n",
    "        ):\n",
    "            logger.info(f\"Stopped due Early Stop condition, last epoch: {epoch}\")\n",
    "            break\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "\n",
    "def train_delight_cnn_model(\n",
    "    params: HyperParameters,\n",
    "    options: DelightDatasetOptions,\n",
    "    early_stop: bool = True,\n",
    "    production: bool = False,\n",
    ") -> DelightCnn:\n",
    "    device = \"cpu\" if torch.cuda.is_available() is False else \"cuda\"\n",
    "    batch_size = _get_value_from_parameter(params[\"batch_size\"])\n",
    "    net_options = get_delight_cnn_parameters(params, options)\n",
    "    net = DelightCnn(net_options)\n",
    "\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=params[\"lr\"], weight_decay=1e-4)\n",
    "    checkpoint = cast(Checkpoint | None, train.get_checkpoint())  # type: ignore\n",
    "    start_epoch = 0\n",
    "\n",
    "    if checkpoint:\n",
    "        with checkpoint.as_directory() as checkpoint_dir:\n",
    "            checkpoint_dict = torch.load(os.path.join(checkpoint_dir, \"checkpoint.pt\"))  # type: ignore\n",
    "            start_epoch = int(checkpoint_dict[\"epoch\"]) + 1\n",
    "            net.load_state_dict(checkpoint_dict[\"net_state_dict\"])\n",
    "            optimizer.load_state_dict(checkpoint_dict[\"optimizer_state_dict\"])\n",
    "\n",
    "    train_dtype = DelightDatasetType.P_TRAIN if production else DelightDatasetType.TRAIN\n",
    "    val_dtype = (\n",
    "        DelightDatasetType.P_VAL if production else DelightDatasetType.VALIDATION\n",
    "    )\n",
    "\n",
    "    train_dataset = DelightDataset(options=options, datatype=train_dtype)\n",
    "    val_dataset = DelightDataset(options=options, datatype=val_dtype)\n",
    "\n",
    "    train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    val_dl = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    logging.basicConfig()\n",
    "    logger = logging.getLogger(\"Training\")\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "\n",
    "    logger.info(\n",
    "        \"Starting: epochs=%s,batch_size=%s,lr=%s,nconv1=%s,nconv2=%s,nconv3=%s,ndense=%s,dropout=%s\"\n",
    "        % (\n",
    "            params[\"epochs\"],\n",
    "            batch_size,\n",
    "            params[\"lr\"],\n",
    "            net_options[\"nconv1\"],\n",
    "            net_options[\"nconv2\"],\n",
    "            net_options[\"nconv3\"],\n",
    "            net_options[\"ndense\"],\n",
    "            net_options[\"dropout\"],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    _train(\n",
    "        start_epoch=start_epoch,\n",
    "        num_epochs=params[\"epochs\"],\n",
    "        device=device,\n",
    "        train_dl=train_dl,\n",
    "        val_dl=val_dl,\n",
    "        optimizer=optimizer,\n",
    "        model=net,\n",
    "        criterion=criterion,\n",
    "        is_ray=checkpoint is not None,\n",
    "        logger=logger,\n",
    "        early_stop=early_stop,\n",
    "    )\n",
    "\n",
    "    return net\n",
    "\n",
    "\n",
    "def evaluate_delight_cnn_model_torch_based(\n",
    "    model: DelightCnn, options: DelightDatasetOptions\n",
    ") -> tuple[npt.NDArray[np.float32], npt.NDArray[np.float32]]:\n",
    "    device = \"cpu\" if torch.cuda.is_available() is False else \"cuda\"\n",
    "    dataset = DelightDataset(\n",
    "        options=options, datatype=DelightDatasetType.TEST, transform_y=False\n",
    "    )\n",
    "    dl = DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "    print(\"Evaluating model...\")\n",
    "    predictions: list[tuple[float, float]] = []\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    inputs: torch.Tensor\n",
    "    outputs: torch.Tensor\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(dl):\n",
    "            inputs, _ = data\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            derotated = DelightDataset.derotate(outputs.cpu().numpy())\n",
    "            y_hat: npt.NDArray[np.float32] = np.mean(derotated, axis=1)\n",
    "            predictions.extend(y_hat.tolist())\n",
    "\n",
    "    y_true: npt.NDArray[np.float32] = dataset.y.cpu().numpy()\n",
    "    y_pred: npt.NDArray[np.float32] = np.array(predictions)\n",
    "\n",
    "    return y_true, y_pred\n",
    "\n",
    "\n",
    "def evaluate_delight_cnn_model_tf_based(\n",
    "    model: tf.keras.Model, options: DelightDatasetOptions\n",
    ") -> tuple[npt.NDArray[np.float32], npt.NDArray[np.float32]]:\n",
    "    X_test, y_test = DelightDataset.get_test_data(options)\n",
    "    y_all_pred = model.predict([X_test[:, :, :, i] for i in range(X_test.shape[3])])\n",
    "    y_pred = np.mean(DelightDataset.derotate(y_all_pred), axis=1)\n",
    "\n",
    "    return y_test, y_pred\n",
    "\n",
    "\n",
    "def calculate_delight_metrics(\n",
    "    y_true: npt.NDArray[np.float32], y_pred: npt.NDArray[np.float32]\n",
    ") -> EvaluationResult:\n",
    "    pixscale = 0.25\n",
    "\n",
    "    _rmse, _rmse_std = rmse(y_true, y_pred, pixscale)\n",
    "    _mean, _mean_std = mean_deviation(y_true, y_pred, pixscale)\n",
    "    _median, _median_std = median_deviation(y_true, y_pred, pixscale)\n",
    "    _mode, _mode_std = mode_deviation(y_true, y_pred, pixscale)\n",
    "\n",
    "    return {\n",
    "        \"rmse\": (round(_rmse, 3), round(_rmse_std, 3)),\n",
    "        \"mean_deviation\": (round(_mean, 3), round(_mean_std, 3)),\n",
    "        \"median_deviation\": (round(_median, 3), round(_median_std, 3)),\n",
    "        \"mode_deviation\": (round(_mode, 3), round(_mode_std, 3)),\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_delight_cnn_model(\n",
    "    model: DelightCnn | tf.keras.Model, options: DelightDatasetOptions\n",
    ") -> EvaluationResult:\n",
    "    if isinstance(model, torch.nn.Module):\n",
    "        print(\"Evaluating delight model based on pytorch\")\n",
    "        y_true, y_pred = evaluate_delight_cnn_model_torch_based(model, options)\n",
    "    else:\n",
    "        print(\"Evaluating delight model based on TensorFlow\")\n",
    "        y_true, y_pred = evaluate_delight_cnn_model_tf_based(model, options)\n",
    "\n",
    "    return calculate_delight_metrics(y_true, y_pred)\n",
    "\n",
    "\n",
    "Environment = Literal[\"cuda\"] | Literal[\"cpu\"]\n",
    "\n",
    "\n",
    "def benchmark_delight_cnn_model_torch_based(\n",
    "    model: DelightCnn, options: DelightDatasetOptions, batch_size: int, env: Environment\n",
    ") -> list[float]:\n",
    "    assert torch.cuda.is_available() is True, \"Pytorch: No cuda detected\"\n",
    "    dataset = DelightDataset(\n",
    "        options=options, datatype=DelightDatasetType.TEST, transform_y=False\n",
    "    )\n",
    "    dl = DataLoader(dataset, batch_size=batch_size)\n",
    "    times: list[float] = []\n",
    "\n",
    "    model.to(env)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(dl):\n",
    "            inputs, _ = data\n",
    "            inputs = inputs.to(env)\n",
    "            ti = time.perf_counter()\n",
    "            model(inputs)\n",
    "            tfinal = time.perf_counter()\n",
    "            dt = (tfinal - ti) * 10e2  # ms\n",
    "\n",
    "            times.append(dt / batch_size)  # time per image\n",
    "\n",
    "    return times\n",
    "\n",
    "\n",
    "def benchmark_delight_cnn_model_tf_based(\n",
    "    model: tf.keras.Model,\n",
    "    options: DelightDatasetOptions,\n",
    "    batch_size: int,\n",
    "    env: Environment,\n",
    ") -> list[float]:\n",
    "    dataset = DelightDataset(\n",
    "        options=options, datatype=DelightDatasetType.TEST, transform_y=False\n",
    "    )\n",
    "\n",
    "    tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "    if env == \"cpu\":\n",
    "        print(\"tf using cpu\")\n",
    "        times = __benckmark_delight_cnn_model_tf_based_cpu(model, dataset, batch_size)\n",
    "    else:\n",
    "        print(\"tf use gpu\")\n",
    "        times = __benckmark_delight_cnn_model_tf_based_gpu(model, dataset, batch_size)\n",
    "\n",
    "    tf.debugging.set_log_device_placement(False)\n",
    "    return times\n",
    "\n",
    "\n",
    "def __benckmark_delight_cnn_model_tf_based_gpu(\n",
    "    model: tf.keras.Model, dataset: DelightDataset, batch_size: int\n",
    ") -> list[float]:\n",
    "    AVAILABLES_GPU = tf.config.list_physical_devices(\"GPU\")\n",
    "    assert (\n",
    "        len(AVAILABLES_GPU) == 1\n",
    "    ), \"Tensorflow: No GPU Devices where found: {}\".format(AVAILABLES_GPU)\n",
    "    tf.config.set_visible_devices(AVAILABLES_GPU[0], \"GPU\")\n",
    "\n",
    "    times: list[float] = []\n",
    "    dl = tf.data.Dataset.from_tensor_slices(dataset.to_tf_dataset()).batch(batch_size)\n",
    "    for X_batch, _ in dl:\n",
    "        X_input = [X_batch[:, :, :, i] for i in range(X_batch.shape[3])]\n",
    "        ti = time.perf_counter()\n",
    "        model.predict(X_input, verbose=None)\n",
    "        tfinal = time.perf_counter()\n",
    "        dt = (tfinal - ti) * 10e2\n",
    "        times.append(dt / batch_size)  # time per image\n",
    "\n",
    "    return times\n",
    "\n",
    "\n",
    "def __benckmark_delight_cnn_model_tf_based_cpu(\n",
    "    model: tf.keras.Model, dataset: DelightDataset, batch_size: int\n",
    ") -> list[float]:\n",
    "    times: list[float] = []\n",
    "    with tf.device(\"/CPU:0\"):\n",
    "        dl = tf.data.Dataset.from_tensor_slices(dataset.to_tf_dataset()).batch(\n",
    "            batch_size\n",
    "        )\n",
    "        for X_batch, _ in dl:\n",
    "            X_input = [X_batch[:, :, :, i] for i in range(X_batch.shape[3])]\n",
    "            ti = time.perf_counter()\n",
    "            model.predict(X_input, verbose=None)\n",
    "            tfinal = time.perf_counter()\n",
    "            dt = (tfinal - ti) * 10e2\n",
    "            times.append(dt / batch_size)  # time per image\n",
    "\n",
    "    return times\n",
    "\n",
    "\n",
    "def benchmark_delight_cnn_model(\n",
    "    model: DelightCnn | tf.keras.Model,\n",
    "    options: DelightDatasetOptions,\n",
    "    batches: list[int],\n",
    ") -> dict[int, tuple[float, float]]:\n",
    "    data: dict[int, tuple[float, float]] = {}\n",
    "    environments: list[Environment] = [\"cuda\", \"cpu\"]\n",
    "    is_pytorch_model = isinstance(model, torch.nn.Module)\n",
    "\n",
    "    for batch_size in batches:\n",
    "        cpu_gpu_times = {\"cuda\": 0.0, \"cpu\": 0.0}\n",
    "\n",
    "        for device in environments:\n",
    "            if is_pytorch_model:\n",
    "                times = benchmark_delight_cnn_model_torch_based(\n",
    "                    model, options, batch_size, device\n",
    "                )\n",
    "            else:\n",
    "                times = benchmark_delight_cnn_model_tf_based(\n",
    "                    model, options, batch_size, device\n",
    "                )\n",
    "            cpu_gpu_times[device] = np.mean(times).item()\n",
    "        data[batch_size] = (cpu_gpu_times[\"cuda\"], cpu_gpu_times[\"cpu\"])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = DelightDatasetOptions(\n",
    "    source=os.path.join(os.getcwd(), \"data\"),\n",
    "    n_levels=5,\n",
    "    fold=0,\n",
    "    mask=False,\n",
    "    object=True,\n",
    "    rot=True,\n",
    "    flip=True,\n",
    "    balance=True,\n",
    ")\n",
    "\n",
    "params_paper: HyperParameters = {\n",
    "    \"nconv1\": 52,\n",
    "    \"nconv2\": 57,\n",
    "    \"nconv3\": 41,\n",
    "    \"ndense\": 685,\n",
    "    \"dropout\": 0.06,\n",
    "    \"epochs\": 100,\n",
    "    \"batch_size\": 40,\n",
    "    \"lr\": 0.0014,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 3672049), started 4 days, 22:44:47 ago. (Use '!kill 3672049' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-fa026235a4f419db\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-fa026235a4f419db\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=runs\n",
    "\n",
    "model_path = os.path.join(\n",
    "    os.getcwd(), \"weights\", \"DelightPt\", \"delight-pt-prod-paper-params-100-epochs.pt\"\n",
    ")\n",
    "if not os.path.exists(model_path):\n",
    "    model = train_delight_cnn_model(\n",
    "        params_paper, options, production=True, early_stop=False\n",
    "    )\n",
    "    torch.save(model, model_path)  # type: ignore\n",
    "else:\n",
    "    model: DelightCnn = torch.load(model_path)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-19 06:13:53.079850: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14965 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB MIG 4g.20gb, pci bus id: 0000:82:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# paper_model_filename = \"final_parallel_rot_balanceTrue_dropout0.06_conv52-57-41_dense685.h5\"\n",
    "paper_model_filename = \"DELIGHT_v1.h5\"\n",
    "\n",
    "paper_model_path = os.path.join(\n",
    "    os.getcwd(), \"weights\", \"DelightTf\", paper_model_filename\n",
    ")\n",
    "\n",
    "paper_model = tf.keras.models.load_model(paper_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating delight model based on TensorFlow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-19 06:13:58.426145: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:933] Skipping loop optimization for Merge node with control input: model_16/tf.image.rot90_507/rot90/Assert/AssertGuard/branch_executed/_8\n",
      "2024-06-19 06:13:58.998294: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 8s 29ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rmse': (1.836, 0.2),\n",
       " 'mean_deviation': (0.783, 0.023),\n",
       " 'median_deviation': (0.468, 0.004),\n",
       " 'mode_deviation': (0.427, 0.063)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_delight_cnn_model(paper_model, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating delight model based on pytorch\n",
      "Evaluating model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rmse': (1.912, 0.212),\n",
       " 'mean_deviation': (0.805, 0.025),\n",
       " 'median_deviation': (0.466, 0.005),\n",
       " 'mode_deviation': (0.427, 0.043)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_delight_cnn_model(model, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = [8, 16, 32, 64, 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf use gpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-19 05:22:00.108423: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:933] Skipping loop optimization for Merge node with control input: model_16/tf.image.rot90_507/rot90/Assert/AssertGuard/branch_executed/_8\n",
      "2024-06-19 05:22:00.783903: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf using cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-19 05:23:21.803965: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:933] Skipping loop optimization for Merge node with control input: model_16/tf.image.rot90_501/rot90/Assert/AssertGuard/branch_executed/_27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf use gpu\n",
      "tf using cpu\n",
      "tf use gpu\n",
      "tf using cpu\n",
      "tf use gpu\n",
      "tf using cpu\n",
      "tf use gpu\n",
      "tf using cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{8: (16.807074002714447, 16.88231772530581),\n",
       " 16: (8.171128504481292, 8.85682766863852),\n",
       " 32: (4.0813424803006155, 4.402423680876382),\n",
       " 64: (2.53009979322087, 2.9705368174472824),\n",
       " 128: (1.6224018560789868, 1.9438261348879773)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_delight_cnn_model(paper_model, options, batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{8: (0.2217104494568571, 13.486206489280303),\n",
       " 16: (0.05534475371023534, 13.898549121368465),\n",
       " 32: (0.029305069862554472, 13.960510232136585),\n",
       " 64: (0.04262963387494286, 13.546825214095103),\n",
       " 128: (0.008970796970013333, 13.1008988732662)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_delight_cnn_model(model, options, batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Busqueda de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import socket\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from telegram import Bot\n",
    "\n",
    "\n",
    "class TelegramNotifier:\n",
    "    def __init__(self, token: str, chat_id: int):\n",
    "        self._bot = Bot(token)\n",
    "        self._chat_id = chat_id\n",
    "\n",
    "    def notify(self, message: str) -> None:\n",
    "        async def notify(bot: Bot, message: str, chat_id: int):\n",
    "            async with bot:\n",
    "                await bot.send_message(\n",
    "                    text=message, parse_mode=\"MarkDown\", chat_id=chat_id\n",
    "                )  # type: ignore\n",
    "\n",
    "        try:\n",
    "            loop = asyncio.get_running_loop()\n",
    "        except RuntimeError:  # 'RuntimeError: There is no current event loop...'\n",
    "            loop = None\n",
    "\n",
    "        if loop and loop.is_running():\n",
    "            print(\n",
    "                \"Async event loop already running. Adding coroutine to the event loop.\"\n",
    "            )\n",
    "            tsk = loop.create_task(notify(self._bot, message, self._chat_id))\n",
    "            # ^-- https://docs.python.org/3/library/asyncio-task.html#task-object\n",
    "            # Optionally, a callback function can be executed when the coroutine completes\n",
    "            tsk.add_done_callback(lambda t: print(\"Message sent\"))\n",
    "        else:\n",
    "            print(\"Starting new event loop\")\n",
    "            asyncio.run(notify(self._bot, message, self._chat_id))\n",
    "\n",
    "\n",
    "def run_ray_tune(*, name: str, num_samples: int, gpus_per_trial: float, source: str):\n",
    "    params = {\n",
    "        \"nconv1\": tune.lograndint(16, 64 + 1),\n",
    "        \"nconv2\": tune.lograndint(16, 64 + 1),\n",
    "        \"nconv3\": tune.lograndint(16, 64 + 1),\n",
    "        \"ndense\": tune.lograndint(256, 2048 + 1),\n",
    "        \"dropout\": tune.uniform(0, 0.4),\n",
    "        \"batch_size\": tune.lograndint(16, 64 + 1),\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-2),\n",
    "        \"epochs\": 100,\n",
    "    }\n",
    "\n",
    "    options = DelightDatasetOptions(\n",
    "        source=source, n_levels=5, fold=0, mask=False, object=True, rot=True, flip=True\n",
    "    )\n",
    "\n",
    "    scheduler = ASHAScheduler(\n",
    "        grace_period=20,  # epochs before evaluate early stop\n",
    "        reduction_factor=3,  # the worst 1/3 trials will be terminated\n",
    "        brackets=1,  # we don't want to decrease resources\n",
    "    )\n",
    "\n",
    "    def train_fn(params: HyperParameters) -> None:\n",
    "        train_delight_cnn_model(params, options, early_stop=False)\n",
    "\n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(train_fn, resources={\"gpu\": gpus_per_trial}),  # type: ignore\n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=\"val_loss\", mode=\"min\", scheduler=scheduler, num_samples=num_samples\n",
    "        ),\n",
    "        run_config=train.RunConfig(name=name),\n",
    "        param_space=params,\n",
    "    )\n",
    "    return tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "name = f\"ray_experiment_{now.strftime('%d_%m_%Y-%H_%M_%S')}\"\n",
    "num_samples = 200\n",
    "machine = socket.gethostname()\n",
    "chat_id = -4049822363\n",
    "token = \"6333721085:AAGbLdRmJsn8TU-gTrSu8npgXNgOaNmBwcs\"\n",
    "notifier = TelegramNotifier(token=token, chat_id=chat_id)\n",
    "sources = {\n",
    "    \"quimal-gpu.alerce.online\": \"/home/kpinochet/delight/data\",\n",
    "    \"LAPTOP-CUH9J3SR\": \"/home/keviinplz/universidad/tesis/astro-delight/data\",\n",
    "}\n",
    "\n",
    "default_source = \"/home/keviinplz/universidad/tesis/astro-delight/data\"\n",
    "\n",
    "message = f\"\"\"\n",
    "**Experimento `{name}` iniciado el día {now.strftime('%d-%m-%Y a las %H:%M:%S')} UTC**\n",
    "\n",
    "Información del experimento:\n",
    "\n",
    "```\n",
    "Pruebas: {num_samples}\n",
    "Máquina: {socket.gethostname()}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "notifier.notify(message)\n",
    "\n",
    "try:\n",
    "    result = run_ray_tune(\n",
    "        name=name,\n",
    "        num_samples=num_samples,\n",
    "        gpus_per_trial=1,\n",
    "        source=sources.get(machine, default_source),\n",
    "    )\n",
    "except Exception as e:\n",
    "    finish = datetime.datetime.now()\n",
    "    message = f\"\"\"\n",
    "    **El experimento `{name}` ha fallado**\n",
    "\n",
    "    Razon: {str(e)}\n",
    " \n",
    "    Este experimento se ha ejecutado en la máquina {socket.gethostname()}\n",
    "    Y fue iniciado el día {now.strftime('%d-%m-%Y a las %H:%M:%S')} UTC\n",
    "    Finalizando el día {finish.strftime('%d-%m-%Y a las %H:%M:%S')} UTC\n",
    "\n",
    "    \"\"\"\n",
    "    notifier.notify(message)\n",
    "    sys.exit(1)\n",
    "\n",
    "finish = datetime.datetime.now()\n",
    "\n",
    "df = result.get_dataframe()\n",
    "\n",
    "df_folder = os.path.join(os.getcwd(), \"ray_results_df\")\n",
    "os.makedirs(df_folder, exist_ok=True)\n",
    "\n",
    "df_filename = os.path.join(df_folder, name + \".pkl\")\n",
    "result_path = \"/\".join(result.get_best_result().path.split(\"/\")[:-1])\n",
    "df.to_pickle(df_filename)\n",
    "\n",
    "best_quantity = 10\n",
    "data = (\n",
    "    df.sort_values(by=[\"val_loss\"])[[\"val_loss\", \"train_loss\"]]\n",
    "    .head(best_quantity)\n",
    "    .to_dict(orient=\"records\")\n",
    ")  # type: ignore\n",
    "\n",
    "rows = \"\"\n",
    "for i, d in enumerate(data):\n",
    "    rows += f'    |   {i+1}  |  {round(d[\"val_loss\"],3)}  |    {round(d[\"train_loss\"],3)}   |\\n'\n",
    "\n",
    "message = f\"\"\"\n",
    "**El experimento `{name}` ha finalizado**\n",
    "\n",
    "Mejores {len(data)} resultados:\n",
    "\n",
    "```\n",
    "| Rank | val_loss | train_loss |\n",
    "|------|:--------:|:----------:|\n",
    "{rows}\n",
    "```\n",
    "\n",
    "Este experimento se ha ejecutado en la máquina {socket.gethostname()}\n",
    "Y fue iniciado el día {now.strftime('%d-%m-%Y a las %H:%M:%S')} UTC\n",
    "Finalizando el día {finish.strftime('%d-%m-%Y a las %H:%M:%S')} UTC\n",
    "\n",
    "Se ha guardado un dataframe con los resultados en `{df_filename}`\n",
    "\n",
    "A su vez, el experimento se encuentra en `{result_path}`\n",
    "\"\"\"\n",
    "notifier.notify(message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
