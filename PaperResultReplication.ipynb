{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción\n",
    "\n",
    "En el presente notebook, buscaremos reproducir los resultados obtenidos en el paper de [DELIGHT](https://arxiv.org/pdf/2208.04310).\n",
    "\n",
    "Para esto, trabajaremos adaptando el modelo propuesto a PyTorch, y mediremos su rendimiento bajo las métricas propuestas por el paper.\n",
    "\n",
    "# Métricas\n",
    "\n",
    "Evaluaremos el desempeño de la red mediante 6 métricas sobre el conjunto de test\n",
    "\n",
    "- $$ RMSE = \\sqrt{MSE} = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} (Y_i - \\hat{Y_i})^2} $$\n",
    "- $$ Mean Deviaton = \\frac{1}{N} \\sum_{i=1}^{N} \\lVert Y_i - \\hat{Y_i} \\rVert $$\n",
    "- $$ Median Deviaton = mediana(\\lVert Y_i - \\hat{Y_i} \\rVert) $$\n",
    "- $$ Mode Deviaton = moda(\\lVert Y_i - \\hat{Y_i} \\rVert) $$\n",
    "\n",
    "Donde:\n",
    "- $N$: Es el tamaño total de los datos del conjunto de test.\n",
    "- $Y_i$: Es un vector 2d que representa la posición real de la galaxia host. $Y_i = (x_i, y_i)$\n",
    "- $\\hat{Y_i }$: Es un vector 2d que representa la posición predicha de la galaxia host. $\\hat{Y_i} = (\\hat{x_i}, \\hat{y_i})$\n",
    "\n",
    "# Baseline\n",
    "\n",
    "Los valores obtenidos para cada métrica en el paper son:\n",
    "- RMSE: 1.836 ± 0.05100\n",
    "- Mean Deviation: 0.783 ± 0.00900\n",
    "- Median Deviation: 0.468 ± 0.00800\n",
    "- Mode Deviation: 0.427 ± 0.05100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext tensorboard\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from typing import Callable\n",
    "from scipy import stats  # type: ignore\n",
    "from sklearn.utils import resample  # type: ignore\n",
    "\n",
    "StatisticFunction = Callable[[npt.NDArray[np.float32]], float]\n",
    "\n",
    "\n",
    "def bootstrap_statistic(\n",
    "    data: npt.NDArray[np.float32],\n",
    "    statistic: StatisticFunction,\n",
    "    n_iterations: int = 1000,\n",
    ") -> float:\n",
    "    stats = np.zeros(n_iterations)\n",
    "    for i in range(n_iterations):\n",
    "        sample: npt.NDArray[np.float32] = resample(data)  # type: ignore\n",
    "        stats[i] = statistic(sample)\n",
    "    return np.std(stats).item()\n",
    "\n",
    "\n",
    "def rmse(\n",
    "    y_true: npt.NDArray[np.float32], y_pred: npt.NDArray[np.float32]\n",
    ") -> tuple[float, float]:\n",
    "    has_shape_2 = len(y_true.shape) == len(y_pred.shape) == 2\n",
    "    are_points = y_true.shape[1] == y_pred.shape[1] == 2\n",
    "    assert (\n",
    "        has_shape_2 and are_points\n",
    "    ), f\"Expected vectors of dim (N, 2): y_true={y_true.shape} y_pred={y_pred.shape}\"\n",
    "\n",
    "    sum_distance_squared: npt.NDArray[np.float32] = np.sum(\n",
    "        (y_true - y_pred) ** 2, axis=1\n",
    "    )\n",
    "    value = np.sqrt(np.mean(sum_distance_squared))  # type: ignore\n",
    "    assert isinstance(value, float), f\"Expected float result: {value}\"\n",
    "    return value, bootstrap_statistic(\n",
    "        sum_distance_squared, lambda x: np.sqrt(np.mean(x))\n",
    "    )\n",
    "\n",
    "\n",
    "def mean_deviation(\n",
    "    y_true: npt.NDArray[np.float32], y_pred: npt.NDArray[np.float32]\n",
    ") -> tuple[float, float]:\n",
    "    has_shape_2 = len(y_true.shape) == len(y_pred.shape) == 2\n",
    "    are_points = y_true.shape[1] == y_pred.shape[1] == 2\n",
    "    assert (\n",
    "        has_shape_2 and are_points\n",
    "    ), f\"Expected vectors of dim (N, 2): y_true={y_true.shape} y_pred={y_pred.shape}\"\n",
    "\n",
    "    deviation: npt.NDArray[np.float32] = np.linalg.norm(y_true - y_pred, axis=1)  # type: ignore\n",
    "    return np.mean(deviation).item(), bootstrap_statistic(deviation, np.mean)\n",
    "\n",
    "\n",
    "def median_deviation(\n",
    "    y_true: npt.NDArray[np.float32], y_pred: npt.NDArray[np.float32]\n",
    ") -> tuple[float, float]:\n",
    "    has_shape_2 = len(y_true.shape) == len(y_pred.shape) == 2\n",
    "    are_points = y_true.shape[1] == y_pred.shape[1] == 2\n",
    "    assert (\n",
    "        has_shape_2 and are_points\n",
    "    ), f\"Expected vectors of dim (N, 2): y_true={y_true.shape} y_pred={y_pred.shape}\"\n",
    "\n",
    "    deviation: npt.NDArray[np.float32] = np.linalg.norm(y_true - y_pred, axis=1)  # type: ignore\n",
    "    return np.median(deviation).item(), bootstrap_statistic(deviation, np.median)\n",
    "\n",
    "\n",
    "def mode_deviation(\n",
    "    y_true: npt.NDArray[np.float32], y_pred: npt.NDArray[np.float32]\n",
    ") -> tuple[float, float]:\n",
    "    has_shape_2 = len(y_true.shape) == len(y_pred.shape) == 2\n",
    "    are_points = y_true.shape[1] == y_pred.shape[1] == 2\n",
    "    assert (\n",
    "        has_shape_2 and are_points\n",
    "    ), f\"Expected vectors of dim (N, 2): y_true={y_true.shape} y_pred={y_pred.shape}\"\n",
    "\n",
    "    deviation: npt.NDArray[np.float32] = np.linalg.norm(y_true - y_pred, axis=1)  # type: ignore\n",
    "    mode = stats.mode(deviation, axis=None).mode  # type: ignore\n",
    "    return mode, bootstrap_statistic(\n",
    "        deviation,\n",
    "        lambda x: stats.mode(x).mode,  # type: ignore\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import OrderedDict\n",
    "from typing import TypedDict\n",
    "from functools import reduce\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "class DelightCnnParameters(TypedDict):\n",
    "    nconv1: int\n",
    "    nconv2: int\n",
    "    nconv3: int\n",
    "    ndense: int\n",
    "    levels: int\n",
    "    dropout: float\n",
    "    rot: bool\n",
    "    flip: bool\n",
    "\n",
    "\n",
    "class RotationAndFlipLayer(torch.nn.Module):\n",
    "    def __init__(self, rot: bool = True, flip: bool = True):\n",
    "        super().__init__()  # type: ignore\n",
    "        self.rot = rot\n",
    "        self.flip = flip\n",
    "        self.n_transforms = (int(flip) + 1) * (3 * int(rot) + 1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        stacked = reduce(lambda x, y: x * y, x.shape[:-3], 1)\n",
    "\n",
    "        if self.rot is False and self.flip is False:\n",
    "            x = x.reshape(stacked, x.shape[-3], x.shape[-2], x.shape[-1])\n",
    "            return x\n",
    "\n",
    "        w_dim = len(x.shape) - 2\n",
    "        h_dim = len(x.shape) - 1\n",
    "        transforms: tuple[torch.Tensor, ...]\n",
    "\n",
    "        if self.rot is False:\n",
    "            flipped = x.flip(dims=(h_dim,))\n",
    "            transforms = (x, flipped)\n",
    "\n",
    "        elif self.flip is False:\n",
    "            rot90 = x.rot90(k=1, dims=(w_dim, h_dim))\n",
    "            rot180 = x.rot90(k=2, dims=(w_dim, h_dim))\n",
    "            rot270 = x.rot90(k=3, dims=(w_dim, h_dim))\n",
    "            transforms = (x, rot90, rot180, rot270)\n",
    "\n",
    "        else:\n",
    "            rot90 = x.rot90(k=1, dims=(w_dim, h_dim))\n",
    "            rot180 = x.rot90(k=2, dims=(w_dim, h_dim))\n",
    "            rot270 = x.rot90(k=3, dims=(w_dim, h_dim))\n",
    "            flipped = x.flip(dims=(h_dim,))\n",
    "            flipped_rot90 = flipped.rot90(k=1, dims=(w_dim, h_dim))\n",
    "            flipped_rot180 = flipped.rot90(k=2, dims=(w_dim, h_dim))\n",
    "            flipped_rot270 = flipped.rot90(k=3, dims=(w_dim, h_dim))\n",
    "            transforms = (\n",
    "                x,\n",
    "                rot90,\n",
    "                rot180,\n",
    "                rot270,\n",
    "                flipped,\n",
    "                flipped_rot90,\n",
    "                flipped_rot180,\n",
    "                flipped_rot270,\n",
    "            )\n",
    "\n",
    "        x = torch.cat(transforms, dim=1)\n",
    "        return x.reshape(\n",
    "            stacked * self.n_transforms, x.shape[-3], x.shape[-2], x.shape[-1]\n",
    "        )\n",
    "\n",
    "\n",
    "class DelightCnn(torch.nn.Module):\n",
    "    def __init__(self, options: DelightCnnParameters):\n",
    "        super().__init__()  # type: ignore\n",
    "        bottleneck: OrderedDict[str, torch.nn.Module] = OrderedDict(\n",
    "            [\n",
    "                (\"conv1\", torch.nn.Conv2d(1, options[\"nconv1\"], 3)),\n",
    "                (\"relu1\", torch.nn.ReLU()),\n",
    "                (\"mp1\", torch.nn.MaxPool2d(2)),\n",
    "                (\"conv2\", torch.nn.Conv2d(options[\"nconv1\"], options[\"nconv2\"], 3)),\n",
    "                (\"relu2\", torch.nn.ReLU()),\n",
    "                (\"mp2\", torch.nn.MaxPool2d(2)),\n",
    "                (\"conv3\", torch.nn.Conv2d(options[\"nconv2\"], options[\"nconv3\"], 3)),\n",
    "                (\"relu3\", torch.nn.ReLU()),\n",
    "                (\"flatten\", torch.nn.Flatten()),\n",
    "            ]\n",
    "        )\n",
    "        linear_in = self._compute_dense_features(\n",
    "            levels=options[\"levels\"], bottleneck=bottleneck\n",
    "        )\n",
    "        self.fc1 = torch.nn.Linear(\n",
    "            in_features=linear_in, out_features=options[\"ndense\"]\n",
    "        )\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "        self.dropout = torch.nn.Dropout(p=options[\"dropout\"])\n",
    "        self.fc2 = torch.nn.Linear(in_features=options[\"ndense\"], out_features=2)\n",
    "        self.rot_and_flip = RotationAndFlipLayer(\n",
    "            rot=options[\"rot\"], flip=options[\"flip\"]\n",
    "        )\n",
    "        self.bottleneck = torch.nn.Sequential(bottleneck)\n",
    "\n",
    "    def _compute_dense_features(\n",
    "        self,\n",
    "        *,\n",
    "        bottleneck: OrderedDict[str, torch.nn.Module],\n",
    "        levels: int,\n",
    "    ) -> int:\n",
    "        w = 30\n",
    "        h = 30\n",
    "        conv_out = 0\n",
    "        for layer in bottleneck.values():\n",
    "            k: int\n",
    "            if isinstance(layer, torch.nn.Conv2d):\n",
    "                k = layer.kernel_size[0]\n",
    "                w = w - k + 1\n",
    "                h = h - k + 1\n",
    "                conv_out = layer.out_channels\n",
    "            if isinstance(layer, torch.nn.MaxPool2d):\n",
    "                k = layer.kernel_size  # type: ignore\n",
    "                w = math.floor((w - k) / 2 + 1)\n",
    "                h = math.floor((h - k) / 2 + 1)\n",
    "\n",
    "        return w * h * conv_out * levels\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        batch = x.shape[0]  # TODO: Remove batch dependency\n",
    "\n",
    "        # Apply flips and rotations over level (L) dimension\n",
    "        x = self.rot_and_flip(x)\n",
    "\n",
    "        # Bottleneck\n",
    "        x = self.bottleneck(x)\n",
    "\n",
    "        # Undo transformations\n",
    "        x = x.reshape(batch, self.rot_and_flip.n_transforms, -1)\n",
    "\n",
    "        # Linear\n",
    "        x = self.fc1(x)\n",
    "        x = self.tanh(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x.reshape(batch, self.rot_and_flip.n_transforms * 2)\n",
    "\n",
    "    def derotate(self, y_pred: torch.Tensor) -> npt.NDArray[np.float32]:\n",
    "        y_pred_numpy: npt.NDArray[np.float32] = y_pred.cpu().numpy()\n",
    "        return (\n",
    "            np.dstack(\n",
    "                [\n",
    "                    y_pred_numpy.reshape((y_pred_numpy.shape[0], 8, 2))[:, 0],\n",
    "                    y_pred_numpy.reshape((y_pred_numpy.shape[0], 8, 2))[:, 1, ::-1]\n",
    "                    * [1, -1],\n",
    "                    y_pred_numpy.reshape((y_pred_numpy.shape[0], 8, 2))[:, 2, :]\n",
    "                    * [-1, -1],\n",
    "                    y_pred_numpy.reshape((y_pred_numpy.shape[0], 8, 2))[:, 3, ::-1]\n",
    "                    * [-1, 1],\n",
    "                    y_pred_numpy.reshape((y_pred_numpy.shape[0], 8, 2))[:, 4, :]\n",
    "                    * [1, -1],\n",
    "                    y_pred_numpy.reshape((y_pred_numpy.shape[0], 8, 2))[:, 5, ::-1],\n",
    "                    y_pred_numpy.reshape((y_pred_numpy.shape[0], 8, 2))[:, 6, :]\n",
    "                    * [-1, 1],\n",
    "                    y_pred_numpy.reshape((y_pred_numpy.shape[0], 8, 2))[:, 7, ::-1]\n",
    "                    * [-1, -1],\n",
    "                ]\n",
    "            )\n",
    "            .reshape((y_pred_numpy.shape[0], 2, 8))\n",
    "            .swapaxes(1, 2)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-15 01:50:36.331266: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-15 01:50:36.331320: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-15 01:50:36.332143: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-15 01:50:36.496189: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-15 01:50:37.720831: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "from typing import Any, cast\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.experimental.numpy as tnp  # type: ignore\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class DelightDatasetType(Enum):\n",
    "    TRAIN = \"TRAIN\"\n",
    "    TEST = \"TEST\"\n",
    "    VALIDATION = \"VALIDATION\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DelightDatasetOptions:\n",
    "    source: str\n",
    "    n_levels: int\n",
    "    fold: int\n",
    "    mask: bool\n",
    "    object: bool\n",
    "    rot: bool\n",
    "    flip: bool\n",
    "    balance: bool = True\n",
    "\n",
    "\n",
    "class DelightDataset(Dataset[tuple[torch.Tensor, torch.Tensor]]):\n",
    "    def __init__(\n",
    "        self,\n",
    "        options: DelightDatasetOptions,\n",
    "        datatype: DelightDatasetType,\n",
    "        transform_y: bool = True,\n",
    "    ):\n",
    "        X, y = self.get_data(options, datatype)\n",
    "\n",
    "        self.X = torch.Tensor(X).permute(0, 3, 1, 2)\n",
    "\n",
    "        self.y = (\n",
    "            self.transform(\n",
    "                y,\n",
    "                options.rot,\n",
    "                options.flip,\n",
    "            )\n",
    "            if transform_y\n",
    "            else torch.from_numpy(y)  # type: ignore\n",
    "        )\n",
    "\n",
    "    def get_data(\n",
    "        self, options: DelightDatasetOptions, datatype: DelightDatasetType\n",
    "    ) -> tuple[npt.NDArray[np.float32], npt.NDArray[np.float32]]:\n",
    "        enum = {\n",
    "            DelightDatasetType.TRAIN: self.get_train_data,\n",
    "            DelightDatasetType.VALIDATION: self.get_val_data,\n",
    "            DelightDatasetType.TEST: self.get_test_data,\n",
    "        }\n",
    "\n",
    "        return enum[datatype](options)\n",
    "\n",
    "    def get_train_data(\n",
    "        self, options: DelightDatasetOptions\n",
    "    ) -> tuple[npt.NDArray[np.float32], npt.NDArray[np.float32]]:\n",
    "        nlevels = options.n_levels\n",
    "        ifold = options.fold\n",
    "        domask = options.mask\n",
    "        doobject = options.object\n",
    "        source = options.source\n",
    "        balance = options.balance\n",
    "\n",
    "        oid_train: npt.NDArray[np.str_] = np.load(\n",
    "            os.path.join(\n",
    "                source,\n",
    "                f\"oid_train_nlevels{nlevels}_fold{ifold}_mask{domask}_objects{doobject}.npy\",\n",
    "            ),\n",
    "            allow_pickle=True,\n",
    "        )\n",
    "        y_train: npt.NDArray[np.float32] = np.load(\n",
    "            os.path.join(\n",
    "                source,\n",
    "                f\"y_train_nlevels{nlevels}_fold{ifold}_mask{domask}_objects{doobject}.npy\",\n",
    "            )\n",
    "        )\n",
    "        X_train: npt.NDArray[np.float32] = np.load(\n",
    "            os.path.join(\n",
    "                source,\n",
    "                f\"X_train_nlevels{nlevels}_fold{ifold}_mask{domask}_objects{doobject}.npy\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if balance is False:\n",
    "            return X_train, y_train\n",
    "\n",
    "        # create balanced training set\n",
    "        idxAsiago = np.array(\n",
    "            [i for i in range(oid_train.shape[0]) if oid_train[i][:2] == \"SN\"]\n",
    "        )\n",
    "        idxZTF = np.array(\n",
    "            [i for i in range(oid_train.shape[0]) if oid_train[i][:3] == \"ZTF\"]\n",
    "        )\n",
    "        nimb = int(idxZTF.shape[0] / idxAsiago.shape[0])\n",
    "\n",
    "        idxbal = np.array([], dtype=int)\n",
    "        for i in range(nimb + 1):\n",
    "            idxbal = np.concatenate([idxbal, idxAsiago])\n",
    "            idxbal = np.concatenate(\n",
    "                [\n",
    "                    idxbal,\n",
    "                    idxZTF[\n",
    "                        i * idxAsiago.shape[0] : min(\n",
    "                            idxZTF.shape[0], (i + 1) * idxAsiago.shape[0]\n",
    "                        )\n",
    "                    ],\n",
    "                ]\n",
    "            )\n",
    "        # shuffle inplace\n",
    "        np.random.shuffle(idxbal)\n",
    "\n",
    "        oid_train = oid_train[idxbal]\n",
    "        X_train = X_train[idxbal]\n",
    "        y_train = y_train[idxbal]\n",
    "\n",
    "        return X_train, y_train\n",
    "\n",
    "    def get_val_data(\n",
    "        self, options: DelightDatasetOptions\n",
    "    ) -> tuple[npt.NDArray[np.float32], npt.NDArray[np.float32]]:\n",
    "        nlevels = options.n_levels\n",
    "        ifold = options.fold\n",
    "        domask = options.mask\n",
    "        doobject = options.object\n",
    "        source = options.source\n",
    "        pixscale = 0.25\n",
    "\n",
    "        oid_val: npt.NDArray[np.str_] = np.load(\n",
    "            os.path.join(\n",
    "                source,\n",
    "                f\"oid_val_nlevels{nlevels}_fold{ifold}_mask{domask}_objects{doobject}.npy\",\n",
    "            ),\n",
    "            allow_pickle=True,\n",
    "        )\n",
    "        y_val: npt.NDArray[np.float32] = np.load(\n",
    "            os.path.join(\n",
    "                source,\n",
    "                f\"y_val_nlevels{nlevels}_fold{ifold}_mask{domask}_objects{doobject}.npy\",\n",
    "            )\n",
    "        )\n",
    "        X_val: npt.NDArray[np.float32] = np.load(\n",
    "            os.path.join(\n",
    "                source,\n",
    "                f\"X_val_nlevels{nlevels}_fold{ifold}_mask{domask}_objects{doobject}.npy\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # mask only the validation set (having difficult cases in the training set helps the validation)\n",
    "        distance = np.sqrt(np.sum(y_val**2, axis=1))\n",
    "        mask = (distance * pixscale) < 60\n",
    "        X_val = X_val[mask]\n",
    "        y_val = y_val[mask]\n",
    "        oid_val = oid_val[mask]\n",
    "\n",
    "        return X_val, y_val\n",
    "\n",
    "    def get_test_data(\n",
    "        self, options: DelightDatasetOptions\n",
    "    ) -> tuple[npt.NDArray[np.float32], npt.NDArray[np.float32]]:\n",
    "        nlevels = options.n_levels\n",
    "        domask = options.mask\n",
    "        doobject = options.object\n",
    "        source = options.source\n",
    "\n",
    "        # oid_test = np.load(os.path.join(source, f\"oid_test_nlevels{nlevels}_mask{domask}_objects{doobject}.npy\"), allow_pickle=True)\n",
    "        y_test = np.load(\n",
    "            os.path.join(\n",
    "                source, f\"y_test_nlevels{nlevels}_mask{domask}_objects{doobject}.npy\"\n",
    "            )\n",
    "        )\n",
    "        X_test = np.load(\n",
    "            os.path.join(\n",
    "                source, f\"X_test_nlevels{nlevels}_mask{domask}_objects{doobject}.npy\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return X_test, y_test\n",
    "\n",
    "    @staticmethod\n",
    "    def transform(\n",
    "        y: np.ndarray[Any, np.dtype[np.float32]], rot: bool, flip: bool\n",
    "    ) -> torch.Tensor:\n",
    "        transformed: tuple[np.ndarray[Any, np.dtype[np.float32]], ...]\n",
    "\n",
    "        if rot is False and flip is False:\n",
    "            return torch.Tensor(y)\n",
    "\n",
    "        yflip = cast(np.ndarray[Any, np.dtype[np.float32]], [1, -1] * y)\n",
    "        if rot is False:\n",
    "            transformed = (y, yflip)\n",
    "\n",
    "        y90 = cast(np.ndarray[Any, np.dtype[np.float32]], [-1, 1] * y[:, ::-1])\n",
    "        y180 = cast(np.ndarray[Any, np.dtype[np.float32]], [-1, 1] * y90[:, ::-1])\n",
    "        y270 = cast(np.ndarray[Any, np.dtype[np.float32]], [-1, 1] * y180[:, ::-1])\n",
    "        yflip90 = cast(np.ndarray[Any, np.dtype[np.float32]], [-1, 1] * yflip[:, ::-1])\n",
    "        yflip180 = cast(\n",
    "            np.ndarray[Any, np.dtype[np.float32]], [-1, 1] * yflip90[:, ::-1]\n",
    "        )\n",
    "        yflip270 = cast(\n",
    "            np.ndarray[Any, np.dtype[np.float32]], [-1, 1] * yflip180[:, ::-1]\n",
    "        )\n",
    "\n",
    "        if flip is False:\n",
    "            transformed = (y, y90, y180, y270)\n",
    "        else:\n",
    "            transformed = (y, y90, y180, y270, yflip, yflip90, yflip180, yflip270)\n",
    "\n",
    "        return torch.Tensor(np.concatenate(transformed, axis=1))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        x = self.X[idx]\n",
    "        y = self.y[idx]\n",
    "\n",
    "        if len(x.shape) == 3:  # has no channel information\n",
    "            levels, width, height = x.shape\n",
    "            x = x.reshape(levels, 1, width, height)  # asume 1 channel information\n",
    "        return x, y\n",
    "\n",
    "    def to_tf_dataset(self) -> tuple[tf.Tensor, tf.Tensor]:\n",
    "        X = cast(np.ndarray[Any, np.dtype[np.float32]], self.X.numpy())\n",
    "        y = cast(np.ndarray[Any, np.dtype[np.float32]], self.y.numpy())\n",
    "\n",
    "        return tnp.copy(X.transpose((0, 2, 3, 1))), tnp.copy(y)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from typing import TypedDict\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "from ray import train\n",
    "from ray.train import Checkpoint\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "import logging\n",
    "\n",
    "\n",
    "class HyperParameters(TypedDict):\n",
    "    lr: float\n",
    "    batch_size: int | float\n",
    "    nconv1: int | float\n",
    "    nconv2: int | float\n",
    "    nconv3: int | float\n",
    "    ndense: int | float\n",
    "    dropout: float\n",
    "    epochs: int\n",
    "\n",
    "\n",
    "class EvaluationResult(TypedDict):\n",
    "    rmse: tuple[float, float]\n",
    "    mean_deviation: tuple[float, float]\n",
    "    median_deviation: tuple[float, float]\n",
    "    mode_deviation: tuple[float, float]\n",
    "\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience: int = 1, min_delta: float = 0.0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter: int = 0\n",
    "        self.min_validation_loss = float(\"inf\")\n",
    "\n",
    "    def early_stop(self, validation_loss: float, logger: logging.Logger) -> bool:\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            logger.info(\n",
    "                f\"Validation loss has been improved from {self.min_validation_loss} -> {validation_loss}\"\n",
    "            )\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            logger.info(\n",
    "                f\"Validation loss is not improving. Best val loss={self.min_validation_loss}\"\n",
    "            )\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "\n",
    "def _get_value_from_parameter(parameter: int | float, base: int = 2) -> int:\n",
    "    return int(base**parameter) if isinstance(parameter, float) else parameter\n",
    "\n",
    "\n",
    "def get_delight_cnn_parameters(\n",
    "    params: HyperParameters, options: DelightDatasetOptions\n",
    ") -> DelightCnnParameters:\n",
    "    return {\n",
    "        \"nconv1\": _get_value_from_parameter(params[\"nconv1\"]),\n",
    "        \"nconv2\": _get_value_from_parameter(params[\"nconv2\"]),\n",
    "        \"nconv3\": _get_value_from_parameter(params[\"nconv3\"]),\n",
    "        \"ndense\": _get_value_from_parameter(params[\"ndense\"]),\n",
    "        \"levels\": options.n_levels,\n",
    "        \"dropout\": params[\"dropout\"],\n",
    "        \"rot\": options.rot,\n",
    "        \"flip\": options.flip,\n",
    "    }\n",
    "\n",
    "\n",
    "def _train_one_epoch(\n",
    "    *,\n",
    "    device: str,\n",
    "    train_dl: DataLoader[tuple[torch.Tensor, torch.Tensor]],\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    model: DelightCnn,\n",
    "    criterion: torch.nn.MSELoss,\n",
    "    writer: SummaryWriter,\n",
    "    is_ray: bool,\n",
    "    epoch: int,\n",
    "):\n",
    "    running_loss = 0.0\n",
    "    inputs: torch.Tensor\n",
    "    positions: torch.Tensor\n",
    "    outputs: torch.Tensor\n",
    "    loss: torch.Tensor\n",
    "\n",
    "    model.train()\n",
    "    for i, (inputs, positions) in enumerate(train_dl):\n",
    "        inputs, positions = inputs.to(device), positions.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, positions)\n",
    "        loss.backward()  # type: ignore\n",
    "\n",
    "        optimizer.step()\n",
    "        loss_value = loss.item()\n",
    "\n",
    "        if is_ray is False:\n",
    "            t = epoch * len(train_dl) + i  # type: ignore\n",
    "            writer.add_scalar(\"[MSE Loss]: Train\", loss_value, t)  # type: ignore\n",
    "\n",
    "        running_loss += loss_value * inputs.size(0)\n",
    "\n",
    "    return running_loss / len(train_dl.dataset)  # type: ignore\n",
    "\n",
    "\n",
    "def _validate_train(\n",
    "    *,\n",
    "    device: str,\n",
    "    val_dl: DataLoader[tuple[torch.Tensor, torch.Tensor]],\n",
    "    model: DelightCnn,\n",
    "    criterion: torch.nn.MSELoss,\n",
    "):\n",
    "    running_loss = 0.0\n",
    "    data: tuple[torch.Tensor, torch.Tensor]\n",
    "    outputs: torch.Tensor\n",
    "    loss: torch.Tensor\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(val_dl):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * labels.size(0)\n",
    "\n",
    "    return running_loss / len(val_dl.dataset)  # type: ignore\n",
    "\n",
    "\n",
    "def _train(\n",
    "    *,\n",
    "    start_epoch: int,\n",
    "    num_epochs: int,\n",
    "    device: str,\n",
    "    train_dl: DataLoader[tuple[torch.Tensor, torch.Tensor]],\n",
    "    val_dl: DataLoader[tuple[torch.Tensor, torch.Tensor]],\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    model: DelightCnn,\n",
    "    criterion: torch.nn.MSELoss,\n",
    "    logger: logging.Logger,\n",
    "    early_stop: bool,\n",
    "    is_ray: bool = False,\n",
    "):\n",
    "    model.to(device)\n",
    "    writer = SummaryWriter(\n",
    "        comment=datetime.datetime.now().strftime(\"%Y-%m-%dT%H-%M-%SZ\")\n",
    "    )\n",
    "    early_stopper = EarlyStopper(patience=3, min_delta=0)\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        train_loss = _train_one_epoch(\n",
    "            device=device,\n",
    "            train_dl=train_dl,\n",
    "            optimizer=optimizer,\n",
    "            model=model,\n",
    "            criterion=criterion,\n",
    "            is_ray=is_ray,\n",
    "            writer=writer,\n",
    "            epoch=epoch,\n",
    "        )\n",
    "\n",
    "        val_loss = _validate_train(\n",
    "            device=device, val_dl=val_dl, model=model, criterion=criterion\n",
    "        )\n",
    "\n",
    "        logger.info(\n",
    "            f\"[EPOCH {epoch+1}] train loss = {train_loss} | val_loss = {val_loss}\"\n",
    "        )\n",
    "        metrics = {\"val_loss\": val_loss, \"train_loss\": train_loss}\n",
    "\n",
    "        if is_ray is False:\n",
    "            writer.add_scalars(\"[MSE Loss]: Train / Validation\", metrics, epoch)  # type: ignore\n",
    "        else:\n",
    "            with tempfile.TemporaryDirectory() as tempdir:\n",
    "                torch.save(  # type: ignore\n",
    "                    {\n",
    "                        \"epoch\": epoch,\n",
    "                        \"net_state_dict\": model.state_dict(),\n",
    "                        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                    },\n",
    "                    os.path.join(tempdir, \"checkpoint.pt\"),\n",
    "                )\n",
    "                train.report(\n",
    "                    metrics=metrics, checkpoint=Checkpoint.from_directory(tempdir)\n",
    "                )  # type: ignore\n",
    "\n",
    "        if early_stop and early_stopper.early_stop(\n",
    "            validation_loss=val_loss, logger=logger\n",
    "        ):\n",
    "            logger.info(f\"Stopped due Early Stop condition, last epoch: {epoch}\")\n",
    "            break\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "\n",
    "def train_delight_cnn_model(\n",
    "    params: HyperParameters, options: DelightDatasetOptions, early_stop: bool = True\n",
    ") -> DelightCnn:\n",
    "    device = \"cpu\" if torch.cuda.is_available() is False else \"cuda\"\n",
    "    batch_size = _get_value_from_parameter(params[\"batch_size\"])\n",
    "    net_options = get_delight_cnn_parameters(params, options)\n",
    "    net = DelightCnn(net_options)\n",
    "\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=params[\"lr\"], weight_decay=1e-4)\n",
    "    checkpoint = cast(Checkpoint | None, train.get_checkpoint())  # type: ignore\n",
    "    start_epoch = 0\n",
    "\n",
    "    if checkpoint:\n",
    "        with checkpoint.as_directory() as checkpoint_dir:\n",
    "            checkpoint_dict = torch.load(os.path.join(checkpoint_dir, \"checkpoint.pt\"))  # type: ignore\n",
    "            start_epoch = int(checkpoint_dict[\"epoch\"]) + 1\n",
    "            net.load_state_dict(checkpoint_dict[\"net_state_dict\"])\n",
    "            optimizer.load_state_dict(checkpoint_dict[\"optimizer_state_dict\"])\n",
    "\n",
    "    train_dataset = DelightDataset(options=options, datatype=DelightDatasetType.TRAIN)\n",
    "    val_dataset = DelightDataset(\n",
    "        options=options, datatype=DelightDatasetType.VALIDATION\n",
    "    )\n",
    "    train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "    val_dl = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    logging.basicConfig()\n",
    "    logger = logging.getLogger(\"Training\")\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "\n",
    "    logger.info(\n",
    "        \"Starting: epochs=%s,batch_size=%s,lr=%s,nconv1=%s,nconv2=%s,nconv3=%s,ndense=%s,dropout=%s\"\n",
    "        % (\n",
    "            params[\"epochs\"],\n",
    "            batch_size,\n",
    "            params[\"lr\"],\n",
    "            net_options[\"nconv1\"],\n",
    "            net_options[\"nconv2\"],\n",
    "            net_options[\"nconv3\"],\n",
    "            net_options[\"ndense\"],\n",
    "            net_options[\"dropout\"],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    _train(\n",
    "        start_epoch=start_epoch,\n",
    "        num_epochs=params[\"epochs\"],\n",
    "        device=device,\n",
    "        train_dl=train_dl,\n",
    "        val_dl=val_dl,\n",
    "        optimizer=optimizer,\n",
    "        model=net,\n",
    "        criterion=criterion,\n",
    "        is_ray=checkpoint is not None,\n",
    "        logger=logger,\n",
    "        early_stop=early_stop,\n",
    "    )\n",
    "\n",
    "    return net\n",
    "\n",
    "\n",
    "def evaluate_delight_cnn_model(\n",
    "    model: DelightCnn, options: DelightDatasetOptions\n",
    ") -> EvaluationResult:\n",
    "    device = \"cpu\" if torch.cuda.is_available() is False else \"cuda\"\n",
    "    dataset = DelightDataset(\n",
    "        options=options, datatype=DelightDatasetType.TEST, transform_y=False\n",
    "    )\n",
    "    dl = DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "    print(\"Evaluating model...\")\n",
    "    predictions: list[tuple[float, float]] = []\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    inputs: torch.Tensor\n",
    "    outputs: torch.Tensor\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(dl):\n",
    "            inputs, _ = data\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            derotated = model.derotate(outputs)\n",
    "            y_hat: npt.NDArray[np.float32] = np.mean(derotated, axis=1)\n",
    "            predictions.extend(y_hat.tolist())\n",
    "\n",
    "    y_true: npt.NDArray[np.float32] = dataset.y.cpu().numpy()\n",
    "    y_pred: npt.NDArray[np.float32] = np.array(predictions)\n",
    "\n",
    "    return {\n",
    "        \"rmse\": rmse(y_true, y_pred),\n",
    "        \"mean_deviation\": mean_deviation(y_true, y_pred),\n",
    "        \"median_deviation\": median_deviation(y_true, y_pred),\n",
    "        \"mode_deviation\": mode_deviation(y_true, y_pred),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=runs\n",
    "\n",
    "options = DelightDatasetOptions(\n",
    "    source=os.path.join(os.getcwd(), \"data\"),\n",
    "    n_levels=5,\n",
    "    fold=0,\n",
    "    mask=False,\n",
    "    object=True,\n",
    "    rot=True,\n",
    "    flip=True,\n",
    "    balance=True,\n",
    ")\n",
    "\n",
    "params_paper: HyperParameters = {\n",
    "    \"nconv1\": 52,\n",
    "    \"nconv2\": 57,\n",
    "    \"nconv3\": 41,\n",
    "    \"ndense\": 685,\n",
    "    \"dropout\": 0.06,\n",
    "    \"epochs\": 50,\n",
    "    \"batch_size\": 40,\n",
    "    \"lr\": 0.0014,\n",
    "}\n",
    "\n",
    "params: HyperParameters = {\n",
    "    \"nconv1\": 16,\n",
    "    \"nconv2\": 32,\n",
    "    \"nconv3\": 32,\n",
    "    \"ndense\": 128,\n",
    "    \"dropout\": 0,\n",
    "    \"epochs\": 50,\n",
    "    \"batch_size\": 64,\n",
    "    \"lr\": 0.0014,\n",
    "}\n",
    "\n",
    "model = train_delight_cnn_model(params_paper, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = evaluate_delight_cnn_model(model, options)\n",
    "\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Busqueda de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import socket\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from telegram import Bot\n",
    "\n",
    "\n",
    "class TelegramNotifier:\n",
    "    def __init__(self, token: str, chat_id: int):\n",
    "        self._bot = Bot(token)\n",
    "        self._chat_id = chat_id\n",
    "\n",
    "    def notify(self, message: str) -> None:\n",
    "        async def notify(bot: Bot, message: str, chat_id: int):\n",
    "            async with bot:\n",
    "                await bot.send_message(\n",
    "                    text=message, parse_mode=\"MarkDown\", chat_id=chat_id\n",
    "                )  # type: ignore\n",
    "\n",
    "        try:\n",
    "            loop = asyncio.get_running_loop()\n",
    "        except RuntimeError:  # 'RuntimeError: There is no current event loop...'\n",
    "            loop = None\n",
    "\n",
    "        if loop and loop.is_running():\n",
    "            print(\n",
    "                \"Async event loop already running. Adding coroutine to the event loop.\"\n",
    "            )\n",
    "            tsk = loop.create_task(notify(self._bot, message, self._chat_id))\n",
    "            # ^-- https://docs.python.org/3/library/asyncio-task.html#task-object\n",
    "            # Optionally, a callback function can be executed when the coroutine completes\n",
    "            tsk.add_done_callback(lambda t: print(\"Message sent\"))\n",
    "        else:\n",
    "            print(\"Starting new event loop\")\n",
    "            asyncio.run(notify(self._bot, message, self._chat_id))\n",
    "\n",
    "\n",
    "def run_ray_tune(*, name: str, num_samples: int, gpus_per_trial: float, source: str):\n",
    "    params = {\n",
    "        \"nconv1\": tune.lograndint(16, 64 + 1),\n",
    "        \"nconv2\": tune.lograndint(16, 64 + 1),\n",
    "        \"nconv3\": tune.lograndint(16, 64 + 1),\n",
    "        \"ndense\": tune.lograndint(256, 2048 + 1),\n",
    "        \"dropout\": tune.uniform(0, 0.4),\n",
    "        \"batch_size\": tune.lograndint(16, 64 + 1),\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-2),\n",
    "        \"epochs\": 100,\n",
    "    }\n",
    "\n",
    "    options = DelightDatasetOptions(\n",
    "        source=source, n_levels=5, fold=0, mask=False, object=True, rot=True, flip=True\n",
    "    )\n",
    "\n",
    "    scheduler = ASHAScheduler(\n",
    "        grace_period=20,  # epochs before evaluate early stop\n",
    "        reduction_factor=3,  # the worst 1/3 trials will be terminated\n",
    "        brackets=1,  # we don't want to decrease resources\n",
    "    )\n",
    "\n",
    "    def train_fn(params: HyperParameters) -> None:\n",
    "        train_delight_cnn_model(params, options, early_stop=False)\n",
    "\n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(train_fn, resources={\"gpu\": gpus_per_trial}),  # type: ignore\n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=\"val_loss\", mode=\"min\", scheduler=scheduler, num_samples=num_samples\n",
    "        ),\n",
    "        run_config=train.RunConfig(name=name),\n",
    "        param_space=params,\n",
    "    )\n",
    "    return tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-06-15 02:01:00</td></tr>\n",
       "<tr><td>Running for: </td><td>00:10:06.74        </td></tr>\n",
       "<tr><td>Memory:      </td><td>2.6/7.5 GiB        </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 60.000: None | Iter 20.000: None<br>Logical resource usage: 0/16 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name          </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  nconv1</th><th style=\"text-align: right;\">  nconv2</th><th style=\"text-align: right;\">  nconv3</th><th style=\"text-align: right;\">  ndense</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_fn_3a650_00000</td><td>RUNNING </td><td>172.17.177.163:39754</td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">0.235285 </td><td style=\"text-align: right;\">0.00233303 </td><td style=\"text-align: right;\">      57</td><td style=\"text-align: right;\">      55</td><td style=\"text-align: right;\">      27</td><td style=\"text-align: right;\">     668</td></tr>\n",
       "<tr><td>train_fn_3a650_00001</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">          22</td><td style=\"text-align: right;\">0.227047 </td><td style=\"text-align: right;\">0.000148812</td><td style=\"text-align: right;\">      22</td><td style=\"text-align: right;\">      44</td><td style=\"text-align: right;\">      16</td><td style=\"text-align: right;\">    1218</td></tr>\n",
       "<tr><td>train_fn_3a650_00002</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">          27</td><td style=\"text-align: right;\">0.377357 </td><td style=\"text-align: right;\">0.000384833</td><td style=\"text-align: right;\">      46</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">      24</td><td style=\"text-align: right;\">     794</td></tr>\n",
       "<tr><td>train_fn_3a650_00003</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">          17</td><td style=\"text-align: right;\">0.0631622</td><td style=\"text-align: right;\">0.00981663 </td><td style=\"text-align: right;\">      59</td><td style=\"text-align: right;\">      44</td><td style=\"text-align: right;\">      17</td><td style=\"text-align: right;\">     828</td></tr>\n",
       "<tr><td>train_fn_3a650_00004</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">          19</td><td style=\"text-align: right;\">0.0746885</td><td style=\"text-align: right;\">0.00205198 </td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">      31</td><td style=\"text-align: right;\">      21</td><td style=\"text-align: right;\">     416</td></tr>\n",
       "<tr><td>train_fn_3a650_00005</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">          21</td><td style=\"text-align: right;\">0.0522794</td><td style=\"text-align: right;\">0.000291489</td><td style=\"text-align: right;\">      34</td><td style=\"text-align: right;\">      46</td><td style=\"text-align: right;\">      21</td><td style=\"text-align: right;\">     628</td></tr>\n",
       "<tr><td>train_fn_3a650_00006</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">          24</td><td style=\"text-align: right;\">0.149872 </td><td style=\"text-align: right;\">0.00030532 </td><td style=\"text-align: right;\">      24</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">      16</td><td style=\"text-align: right;\">    1233</td></tr>\n",
       "<tr><td>train_fn_3a650_00007</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">          24</td><td style=\"text-align: right;\">0.290728 </td><td style=\"text-align: right;\">0.00537451 </td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">      57</td><td style=\"text-align: right;\">      41</td><td style=\"text-align: right;\">     568</td></tr>\n",
       "<tr><td>train_fn_3a650_00008</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">0.150494 </td><td style=\"text-align: right;\">0.00281034 </td><td style=\"text-align: right;\">      35</td><td style=\"text-align: right;\">      56</td><td style=\"text-align: right;\">      34</td><td style=\"text-align: right;\">     709</td></tr>\n",
       "<tr><td>train_fn_3a650_00009</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">          35</td><td style=\"text-align: right;\">0.0554766</td><td style=\"text-align: right;\">0.00619164 </td><td style=\"text-align: right;\">      43</td><td style=\"text-align: right;\">      23</td><td style=\"text-align: right;\">      35</td><td style=\"text-align: right;\">     955</td></tr>\n",
       "<tr><td>train_fn_3a650_00010</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">          46</td><td style=\"text-align: right;\">0.311202 </td><td style=\"text-align: right;\">0.000181285</td><td style=\"text-align: right;\">      39</td><td style=\"text-align: right;\">      24</td><td style=\"text-align: right;\">      23</td><td style=\"text-align: right;\">     899</td></tr>\n",
       "<tr><td>train_fn_3a650_00011</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">          29</td><td style=\"text-align: right;\">0.0673847</td><td style=\"text-align: right;\">0.000215672</td><td style=\"text-align: right;\">      21</td><td style=\"text-align: right;\">      34</td><td style=\"text-align: right;\">      20</td><td style=\"text-align: right;\">     575</td></tr>\n",
       "<tr><td>train_fn_3a650_00012</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">          20</td><td style=\"text-align: right;\">0.227549 </td><td style=\"text-align: right;\">0.000121397</td><td style=\"text-align: right;\">      19</td><td style=\"text-align: right;\">      51</td><td style=\"text-align: right;\">      37</td><td style=\"text-align: right;\">     855</td></tr>\n",
       "<tr><td>train_fn_3a650_00013</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">          61</td><td style=\"text-align: right;\">0.242896 </td><td style=\"text-align: right;\">0.00912591 </td><td style=\"text-align: right;\">      45</td><td style=\"text-align: right;\">      53</td><td style=\"text-align: right;\">      58</td><td style=\"text-align: right;\">     385</td></tr>\n",
       "<tr><td>train_fn_3a650_00014</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">          27</td><td style=\"text-align: right;\">0.351778 </td><td style=\"text-align: right;\">0.000509308</td><td style=\"text-align: right;\">      41</td><td style=\"text-align: right;\">      41</td><td style=\"text-align: right;\">      28</td><td style=\"text-align: right;\">     576</td></tr>\n",
       "<tr><td>train_fn_3a650_00015</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">0.140509 </td><td style=\"text-align: right;\">0.000238762</td><td style=\"text-align: right;\">      46</td><td style=\"text-align: right;\">      26</td><td style=\"text-align: right;\">      22</td><td style=\"text-align: right;\">     389</td></tr>\n",
       "<tr><td>train_fn_3a650_00016</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">          23</td><td style=\"text-align: right;\">0.0749663</td><td style=\"text-align: right;\">0.00767846 </td><td style=\"text-align: right;\">      33</td><td style=\"text-align: right;\">      23</td><td style=\"text-align: right;\">      64</td><td style=\"text-align: right;\">    1171</td></tr>\n",
       "<tr><td>train_fn_3a650_00017</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">          25</td><td style=\"text-align: right;\">0.284664 </td><td style=\"text-align: right;\">0.000248121</td><td style=\"text-align: right;\">      28</td><td style=\"text-align: right;\">      27</td><td style=\"text-align: right;\">      19</td><td style=\"text-align: right;\">     899</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(pid=39754)\u001b[0m 2024-06-15 01:50:56.267668: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "\u001b[36m(pid=39754)\u001b[0m 2024-06-15 01:50:56.267716: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "\u001b[36m(pid=39754)\u001b[0m 2024-06-15 01:50:56.267741: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\u001b[36m(pid=39754)\u001b[0m 2024-06-15 01:50:56.273533: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[36m(pid=39754)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[36m(pid=39754)\u001b[0m 2024-06-15 01:50:57.003205: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[36m(train_fn pid=39754)\u001b[0m INFO:Training:Starting: epochs=100,batch_size=20,lr=0.0023330290398946496,nconv1=57,nconv2=55,nconv3=27,ndense=668,dropout=0.23528450179042304\n",
      "\u001b[36m(train_fn pid=39754)\u001b[0m INFO:Training:[EPOCH 1] train loss = 353.3815678718645 | val_loss = 60.84908702008467\n",
      "\u001b[36m(train_fn pid=39754)\u001b[0m INFO:Training:[EPOCH 2] train loss = 138.74019817322474 | val_loss = 51.889532384446724\n",
      "\u001b[36m(train_fn pid=39754)\u001b[0m INFO:Training:[EPOCH 3] train loss = 108.0871047836001 | val_loss = 61.01234827530996\n",
      "\u001b[36m(train_fn pid=39754)\u001b[0m INFO:Training:[EPOCH 4] train loss = 90.65149346017293 | val_loss = 46.10394366840845\n",
      "\u001b[36m(train_fn pid=39754)\u001b[0m INFO:Training:[EPOCH 5] train loss = 74.48031794903011 | val_loss = 44.05426212544734\n",
      "\u001b[36m(train_fn pid=39754)\u001b[0m INFO:Training:[EPOCH 6] train loss = 68.74395522796026 | val_loss = 43.179064317400076\n",
      "\u001b[36m(train_fn pid=39754)\u001b[0m INFO:Training:[EPOCH 7] train loss = 64.47166248121967 | val_loss = 42.73145944772783\n",
      "\u001b[36m(train_fn pid=39754)\u001b[0m INFO:Training:[EPOCH 8] train loss = 62.88543057742781 | val_loss = 43.7681486203763\n",
      "\u001b[36m(train_fn pid=39754)\u001b[0m INFO:Training:[EPOCH 9] train loss = 63.3901793020573 | val_loss = 41.44522734726773\n",
      "\u001b[36m(train_fn pid=39754)\u001b[0m INFO:Training:[EPOCH 10] train loss = 58.729157964508005 | val_loss = 46.03392095012768\n",
      "\u001b[36m(train_fn pid=39754)\u001b[0m INFO:Training:[EPOCH 11] train loss = 57.770529416119274 | val_loss = 42.970614914303276\n",
      "\u001b[36m(train_fn pid=39754)\u001b[0m INFO:Training:[EPOCH 12] train loss = 53.867909695825446 | val_loss = 42.4535928160437\n",
      "\u001b[36m(train_fn pid=39754)\u001b[0m INFO:Training:[EPOCH 13] train loss = 51.81525245891303 | val_loss = 43.34284947840532\n",
      "\u001b[36m(train_fn pid=39754)\u001b[0m INFO:Training:[EPOCH 14] train loss = 50.887142979661455 | val_loss = 44.09967202308728\n",
      "\u001b[36m(train_fn pid=39754)\u001b[0m INFO:Training:[EPOCH 15] train loss = 51.551895226474564 | val_loss = 43.103984356125444\n",
      "\u001b[36m(train_fn pid=39754)\u001b[0m INFO:Training:[EPOCH 16] train loss = 50.75938513245987 | val_loss = 41.79105847151418\n",
      "\u001b[36m(train_fn pid=39754)\u001b[0m INFO:Training:[EPOCH 17] train loss = 50.14966698633356 | val_loss = 43.48598061117173\n",
      "\u001b[36m(train_fn pid=39754)\u001b[0m INFO:Training:[EPOCH 18] train loss = 49.38301820462537 | val_loss = 42.70429950661594\n",
      "\u001b[36m(train_fn pid=39754)\u001b[0m INFO:Training:[EPOCH 19] train loss = 47.380857783057785 | val_loss = 41.36005243421546\n",
      "\u001b[36m(train_fn pid=39754)\u001b[0m INFO:Training:[EPOCH 20] train loss = 46.464682553234546 | val_loss = 41.3420516727465\n",
      "\u001b[36m(train_fn pid=39754)\u001b[0m INFO:Training:[EPOCH 21] train loss = 46.209295417340634 | val_loss = 42.06093898832077\n",
      "\u001b[36m(train_fn pid=39754)\u001b[0m INFO:Training:[EPOCH 22] train loss = 49.181640003362624 | val_loss = 40.96526480934547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Async event loop already running. Adding coroutine to the event loop.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'tb_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/delight-6BEqGedw-py3.10/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py:110\u001b[0m, in \u001b[0;36mRayEventManager.resolve_future\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/delight-6BEqGedw-py3.10/lib/python3.10/site-packages/ray/_private/auto_init_hook.py:24\u001b[0m, in \u001b[0;36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m auto_init_ray()\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/delight-6BEqGedw-py3.10/lib/python3.10/site-packages/ray/_private/client_mode_hook.py:103\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/delight-6BEqGedw-py3.10/lib/python3.10/site-packages/ray/_private/worker.py:2565\u001b[0m, in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   2564\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2565\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[1;32m   2567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_individual_id:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: Task was killed due to the node running low on memory.\nMemory on the node (IP: 172.17.177.163, ID: 227f6473ba966ed8118157c67cf731153a2b7d9b1e6a97d25c210079) where the task (actor ID: 7b40738ce83061db8c0c8ee501000000, name=ImplicitFunc.__init__, pid=39754, memory used=4.82GB) was running was 7.09GB / 7.46GB (0.950388), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 3f1b70947ab8a0ba7231c5651e9994bf2c82c8bd12aa6f24caa6276b) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 172.17.177.163`. To see the logs of the worker, use `ray logs worker-3f1b70947ab8a0ba7231c5651e9994bf2c82c8bd12aa6f24caa6276b*out -ip 172.17.177.163. Top 10 memory users:\nPID\tMEM(GB)\tCOMMAND\n39754\t4.82\tray::ImplicitFunc.train\n38581\t0.25\t/home/keviinplz/.cache/pypoetry/virtualenvs/delight-6BEqGedw-py3.10/bin/python -m ipykernel_launcher...\n39130\t0.17\t/home/keviinplz/.cache/pypoetry/virtualenvs/delight-6BEqGedw-py3.10/lib/python3.10/site-packages/ray...\n18217\t0.16\t/home/keviinplz/.vscode-server/bin/611f9bfce64f25108829dd295f54a6894e87339d/node --dns-result-order=...\n39205\t0.13\t/home/keviinplz/.cache/pypoetry/virtualenvs/delight-6BEqGedw-py3.10/lib/python3.10/site-packages/ray...\n19992\t0.05\t/home/keviinplz/.vscode-server/bin/611f9bfce64f25108829dd295f54a6894e87339d/node /home/keviinplz/.vs...\n39309\t0.04\tray::IDLE\n39312\t0.04\tray::IDLE\n39315\t0.04\tray::IDLE\n39304\t0.04\tray::IDLE\nRefer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 31\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 31\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mrun_ray_tune\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgpus_per_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msources\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmachine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_source\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[0;32mIn[6], line 73\u001b[0m, in \u001b[0;36mrun_ray_tune\u001b[0;34m(name, num_samples, gpus_per_trial, source)\u001b[0m\n\u001b[1;32m     65\u001b[0m tuner \u001b[38;5;241m=\u001b[39m tune\u001b[38;5;241m.\u001b[39mTuner(\n\u001b[1;32m     66\u001b[0m     tune\u001b[38;5;241m.\u001b[39mwith_resources(train_fn, resources\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m\"\u001b[39m: gpus_per_trial}),  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     tune_config\u001b[38;5;241m=\u001b[39mtune\u001b[38;5;241m.\u001b[39mTuneConfig(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m     param_space\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m     72\u001b[0m )\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/delight-6BEqGedw-py3.10/lib/python3.10/site-packages/ray/tune/tuner.py:364\u001b[0m, in \u001b[0;36mTuner.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_local_tuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m TuneError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/delight-6BEqGedw-py3.10/lib/python3.10/site-packages/ray/tune/impl/tuner_internal.py:526\u001b[0m, in \u001b[0;36mTunerInternal.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_restored:\n\u001b[0;32m--> 526\u001b[0m     analysis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_space\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/delight-6BEqGedw-py3.10/lib/python3.10/site-packages/ray/tune/impl/tuner_internal.py:645\u001b[0m, in \u001b[0;36mTunerInternal._fit_internal\u001b[0;34m(self, trainable, param_space)\u001b[0m\n\u001b[1;32m    633\u001b[0m args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    634\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tune_run_arguments(trainable),\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tuner_kwargs,\n\u001b[1;32m    644\u001b[0m }\n\u001b[0;32m--> 645\u001b[0m analysis \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclear_remote_string_queue()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/delight-6BEqGedw-py3.10/lib/python3.10/site-packages/ray/tune/tune.py:1007\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, storage_path, storage_filesystem, search_alg, scheduler, checkpoint_config, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, chdir_to_trial_dir, local_dir, _experiment_checkpoint_dir, _remote, _remote_string_queue, _entrypoint)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mis_finished() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m experiment_interrupted_event\u001b[38;5;241m.\u001b[39mis_set():\n\u001b[0;32m-> 1007\u001b[0m     \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_verbosity(Verbosity\u001b[38;5;241m.\u001b[39mV1_EXPERIMENT):\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/delight-6BEqGedw-py3.10/lib/python3.10/site-packages/ray/tune/execution/tune_controller.py:731\u001b[0m, in \u001b[0;36mTuneController.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;66;03m# Handle one event\u001b[39;00m\n\u001b[0;32m--> 731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_actor_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;66;03m# If there are no actors running, warn about potentially\u001b[39;00m\n\u001b[1;32m    733\u001b[0m     \u001b[38;5;66;03m# insufficient resources\u001b[39;00m\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_actor_manager\u001b[38;5;241m.\u001b[39mnum_live_actors:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/delight-6BEqGedw-py3.10/lib/python3.10/site-packages/ray/air/execution/_internal/actor_manager.py:224\u001b[0m, in \u001b[0;36mRayActorManager.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m actor_task_futures:\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_actor_task_events\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolve_future\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/delight-6BEqGedw-py3.10/lib/python3.10/site-packages/ray/air/execution/_internal/event_manager.py:113\u001b[0m, in \u001b[0;36mRayEventManager.resolve_future\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error:\n\u001b[0;32m--> 113\u001b[0m     \u001b[43mon_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/delight-6BEqGedw-py3.10/lib/python3.10/site-packages/ray/air/execution/_internal/actor_manager.py:770\u001b[0m, in \u001b[0;36mRayActorManager._schedule_tracked_actor_task.<locals>.on_error\u001b[0;34m(exception)\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_error\u001b[39m(exception: \u001b[38;5;167;01mException\u001b[39;00m):\n\u001b[0;32m--> 770\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_actor_task_failed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtracked_actor_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtracked_actor_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexception\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/delight-6BEqGedw-py3.10/lib/python3.10/site-packages/ray/air/execution/_internal/actor_manager.py:291\u001b[0m, in \u001b[0;36mRayActorManager._actor_task_failed\u001b[0;34m(self, tracked_actor_task, exception)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    292\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCaught unexpected exception: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexception\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    293\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexception\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught unexpected exception: Task was killed due to the node running low on memory.\nMemory on the node (IP: 172.17.177.163, ID: 227f6473ba966ed8118157c67cf731153a2b7d9b1e6a97d25c210079) where the task (actor ID: 7b40738ce83061db8c0c8ee501000000, name=ImplicitFunc.__init__, pid=39754, memory used=4.82GB) was running was 7.09GB / 7.46GB (0.950388), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 3f1b70947ab8a0ba7231c5651e9994bf2c82c8bd12aa6f24caa6276b) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 172.17.177.163`. To see the logs of the worker, use `ray logs worker-3f1b70947ab8a0ba7231c5651e9994bf2c82c8bd12aa6f24caa6276b*out -ip 172.17.177.163. Top 10 memory users:\nPID\tMEM(GB)\tCOMMAND\n39754\t4.82\tray::ImplicitFunc.train\n38581\t0.25\t/home/keviinplz/.cache/pypoetry/virtualenvs/delight-6BEqGedw-py3.10/bin/python -m ipykernel_launcher...\n39130\t0.17\t/home/keviinplz/.cache/pypoetry/virtualenvs/delight-6BEqGedw-py3.10/lib/python3.10/site-packages/ray...\n18217\t0.16\t/home/keviinplz/.vscode-server/bin/611f9bfce64f25108829dd295f54a6894e87339d/node --dns-result-order=...\n39205\t0.13\t/home/keviinplz/.cache/pypoetry/virtualenvs/delight-6BEqGedw-py3.10/lib/python3.10/site-packages/ray...\n19992\t0.05\t/home/keviinplz/.vscode-server/bin/611f9bfce64f25108829dd295f54a6894e87339d/node /home/keviinplz/.vs...\n39309\t0.04\tray::IDLE\n39312\t0.04\tray::IDLE\n39315\t0.04\tray::IDLE\n39304\t0.04\tray::IDLE\nRefer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[7], line 50\u001b[0m\n\u001b[1;32m     49\u001b[0m     notifier\u001b[38;5;241m.\u001b[39mnotify(message)\n\u001b[0;32m---> 50\u001b[0m     \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m finish \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n",
      "\u001b[0;31mSystemExit\u001b[0m: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/delight-6BEqGedw-py3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2145\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_only:\n\u001b[1;32m   2143\u001b[0m     stb \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn exception has occurred, use \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mtb to see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2144\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe full traceback.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m-> 2145\u001b[0m     stb\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInteractiveTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_exception_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2146\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2149\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontains_exceptiongroup\u001b[39m(val):\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/delight-6BEqGedw-py3.10/lib/python3.10/site-packages/IPython/core/ultratb.py:710\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_exception_only\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype, value):\n\u001b[1;32m    703\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \n\u001b[1;32m    705\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;124;03m    value : exception value\u001b[39;00m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 710\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mListTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/delight-6BEqGedw-py3.10/lib/python3.10/site-packages/IPython/core/ultratb.py:568\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    565\u001b[0m     chained_exc_ids\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(exception[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    566\u001b[0m     chained_exceptions_tb_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    567\u001b[0m     out_list \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 568\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchained_exc_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    572\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchained_exceptions_tb_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;241m+\u001b[39m chained_exception_message\n\u001b[1;32m    576\u001b[0m         \u001b[38;5;241m+\u001b[39m out_list)\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_list\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/delight-6BEqGedw-py3.10/lib/python3.10/site-packages/IPython/core/ultratb.py:1454\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1452\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1453\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb \u001b[38;5;241m=\u001b[39m etb\n\u001b[0;32m-> 1454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1455\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[1;32m   1456\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/delight-6BEqGedw-py3.10/lib/python3.10/site-packages/IPython/core/ultratb.py:1345\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1342\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose_modes:\n\u001b[1;32m   1344\u001b[0m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[0;32m-> 1345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1346\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[1;32m   1347\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListTB\u001b[38;5;241m.\u001b[39mget_exception_only(\u001b[38;5;28mself\u001b[39m, etype, value)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/delight-6BEqGedw-py3.10/lib/python3.10/site-packages/IPython/core/ultratb.py:1192\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstructured_traceback\u001b[39m(\n\u001b[1;32m   1184\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1185\u001b[0m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     number_of_lines_of_context: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m   1190\u001b[0m ):\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1192\u001b[0m     formatted_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m     colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mColors  \u001b[38;5;66;03m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m     colorsnormal \u001b[38;5;241m=\u001b[39m colors\u001b[38;5;241m.\u001b[39mNormal  \u001b[38;5;66;03m# used a lot\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/delight-6BEqGedw-py3.10/lib/python3.10/site-packages/IPython/core/ultratb.py:1082\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tb_offset, \u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m   1080\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_header(\u001b[38;5;28mstr\u001b[39m(etype), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlong_header)\n\u001b[1;32m   1081\u001b[0m records \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1082\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m   1083\u001b[0m )\n\u001b[1;32m   1085\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1086\u001b[0m skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/delight-6BEqGedw-py3.10/lib/python3.10/site-packages/IPython/core/ultratb.py:1150\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[0;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1150\u001b[0m         mod \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetmodule(\u001b[43mcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtb_frame\u001b[49m)\n\u001b[1;32m   1151\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1152\u001b[0m             mod_name \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tb_frame'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message sent\n",
      "Message sent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2024-06-15 02:01:52,691 E 39205 39205] (raylet) node_manager.cc:3035: 2 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 227f6473ba966ed8118157c67cf731153a2b7d9b1e6a97d25c210079, IP: 172.17.177.163) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 172.17.177.163`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-6' coro=<TelegramNotifier.notify.<locals>.notify() done, defined at /tmp/ipykernel_38581/2355518680.py:16> exception=NetworkError('Unknown error in HTTP implementation: RuntimeError('This HTTPXRequest is not initialized!')')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/keviinplz/.cache/pypoetry/virtualenvs/delight-6BEqGedw-py3.10/lib/python3.10/site-packages/telegram/request/_baserequest.py\", line 278, in _request_wrapper\n",
      "    code, payload = await self.do_request(\n",
      "  File \"/home/keviinplz/.cache/pypoetry/virtualenvs/delight-6BEqGedw-py3.10/lib/python3.10/site-packages/telegram/request/_httpxrequest.py\", line 189, in do_request\n",
      "    raise RuntimeError(\"This HTTPXRequest is not initialized!\")\n",
      "RuntimeError: This HTTPXRequest is not initialized!\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_38581/2355518680.py\", line 18, in notify\n",
      "    await bot.send_message(\n",
      "  File \"/home/keviinplz/.cache/pypoetry/virtualenvs/delight-6BEqGedw-py3.10/lib/python3.10/site-packages/telegram/_bot.py\", line 519, in decorator\n",
      "    result = await func(self, *args, **kwargs)  # skipcq: PYL-E1102\n",
      "  File \"/home/keviinplz/.cache/pypoetry/virtualenvs/delight-6BEqGedw-py3.10/lib/python3.10/site-packages/telegram/_bot.py\", line 840, in send_message\n",
      "    return await self._send_message(\n",
      "  File \"/home/keviinplz/.cache/pypoetry/virtualenvs/delight-6BEqGedw-py3.10/lib/python3.10/site-packages/telegram/_bot.py\", line 697, in _send_message\n",
      "    result = await self._post(\n",
      "  File \"/home/keviinplz/.cache/pypoetry/virtualenvs/delight-6BEqGedw-py3.10/lib/python3.10/site-packages/telegram/_bot.py\", line 607, in _post\n",
      "    return await self._do_post(\n",
      "  File \"/home/keviinplz/.cache/pypoetry/virtualenvs/delight-6BEqGedw-py3.10/lib/python3.10/site-packages/telegram/_bot.py\", line 635, in _do_post\n",
      "    return await request.post(\n",
      "  File \"/home/keviinplz/.cache/pypoetry/virtualenvs/delight-6BEqGedw-py3.10/lib/python3.10/site-packages/telegram/request/_baserequest.py\", line 168, in post\n",
      "    result = await self._request_wrapper(\n",
      "  File \"/home/keviinplz/.cache/pypoetry/virtualenvs/delight-6BEqGedw-py3.10/lib/python3.10/site-packages/telegram/request/_baserequest.py\", line 290, in _request_wrapper\n",
      "    raise NetworkError(f\"Unknown error in HTTP implementation: {exc!r}\") from exc\n",
      "telegram.error.NetworkError: Unknown error in HTTP implementation: RuntimeError('This HTTPXRequest is not initialized!')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "name = f\"ray_experiment_{now.strftime('%d_%m_%Y-%H_%M_%S')}\"\n",
    "num_samples = 200\n",
    "machine = socket.gethostname()\n",
    "chat_id = -4049822363\n",
    "token = \"6333721085:AAGbLdRmJsn8TU-gTrSu8npgXNgOaNmBwcs\"\n",
    "notifier = TelegramNotifier(token=token, chat_id=chat_id)\n",
    "sources = {\n",
    "    \"quimal-gpu.alerce.online\": \"/home/kpinochet/delight/data\",\n",
    "    \"LAPTOP-CUH9J3SR\": \"/home/keviinplz/universidad/tesis/astro-delight/data\",\n",
    "}\n",
    "\n",
    "default_source = \"/home/keviinplz/universidad/tesis/astro-delight/data\"\n",
    "\n",
    "message = f\"\"\"\n",
    "**Experimento `{name}` iniciado el día {now.strftime('%d-%m-%Y a las %H:%M:%S')} UTC**\n",
    "\n",
    "Información del experimento:\n",
    "\n",
    "```\n",
    "Pruebas: {num_samples}\n",
    "Máquina: {socket.gethostname()}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "notifier.notify(message)\n",
    "\n",
    "try:\n",
    "    result = run_ray_tune(\n",
    "        name=name,\n",
    "        num_samples=num_samples,\n",
    "        gpus_per_trial=1,\n",
    "        source=sources.get(machine, default_source),\n",
    "    )\n",
    "except Exception as e:\n",
    "    finish = datetime.datetime.now()\n",
    "    message = f\"\"\"\n",
    "    **El experimento `{name}` ha fallado**\n",
    "\n",
    "    Razon: {str(e)}\n",
    " \n",
    "    Este experimento se ha ejecutado en la máquina {socket.gethostname()}\n",
    "    Y fue iniciado el día {now.strftime('%d-%m-%Y a las %H:%M:%S')} UTC\n",
    "    Finalizando el día {finish.strftime('%d-%m-%Y a las %H:%M:%S')} UTC\n",
    "\n",
    "    \"\"\"\n",
    "    notifier.notify(message)\n",
    "    sys.exit(1)\n",
    "\n",
    "finish = datetime.datetime.now()\n",
    "\n",
    "df = result.get_dataframe()\n",
    "\n",
    "df_folder = os.path.join(os.getcwd(), \"ray_results_df\")\n",
    "os.makedirs(df_folder, exist_ok=True)\n",
    "\n",
    "df_filename = os.path.join(df_folder, name + \".pkl\")\n",
    "result_path = \"/\".join(result.get_best_result().path.split(\"/\")[:-1])\n",
    "df.to_pickle(df_filename)\n",
    "\n",
    "best_quantity = 10\n",
    "data = (\n",
    "    df.sort_values(by=[\"val_loss\"])[[\"val_loss\", \"train_loss\"]]\n",
    "    .head(best_quantity)\n",
    "    .to_dict(orient=\"records\")\n",
    ")  # type: ignore\n",
    "\n",
    "rows = \"\"\n",
    "for i, d in enumerate(data):\n",
    "    rows += f'    |   {i+1}  |  {round(d[\"val_loss\"],3)}  |    {round(d[\"train_loss\"],3)}   |\\n'\n",
    "\n",
    "message = f\"\"\"\n",
    "**El experimento `{name}` ha finalizado**\n",
    "\n",
    "Mejores {len(data)} resultados:\n",
    "\n",
    "```\n",
    "| Rank | val_loss | train_loss |\n",
    "|------|:--------:|:----------:|\n",
    "{rows}\n",
    "```\n",
    "\n",
    "Este experimento se ha ejecutado en la máquina {socket.gethostname()}\n",
    "Y fue iniciado el día {now.strftime('%d-%m-%Y a las %H:%M:%S')} UTC\n",
    "Finalizando el día {finish.strftime('%d-%m-%Y a las %H:%M:%S')} UTC\n",
    "\n",
    "Se ha guardado un dataframe con los resultados en `{df_filename}`\n",
    "\n",
    "A su vez, el experimento se encuentra en `{result_path}`\n",
    "\"\"\"\n",
    "notifier.notify(message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "delight-6BEqGedw-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
