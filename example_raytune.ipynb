{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using raytune\n",
    "\n",
    "This notebook shows an example of how to use Raytune with this package to train several configurations of DelightCnn models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import datetime\n",
    "from functools import partial\n",
    "\n",
    "import gdown\n",
    "import torch\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from ray import tune, train\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "from delightcnn.dataset import DelightDataset, DelightDatasetOptions\n",
    "from delightcnn.training import (\n",
    "    ray_wrapper_training_function,\n",
    "    TrainingOptions,\n",
    ")\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"[%(asctime)s %(levelname)s]: %(message)s\",\n",
    "    level=logging.INFO,\n",
    "    stream=sys.stderr,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading dataset used in [Delight Paper](https://arxiv.org/pdf/2208.04310)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://drive.google.com/drive/u/2/folders/1UkHvXq2oNySMN2Hv2K1H9ptygvi2KgdM\"\n",
    "source = os.path.join(os.getcwd(), \"data\")\n",
    "gdown.download_folder(url, output=source, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingSetProcessor:\n",
    "    def __init__(self, source: str, balance: bool = False):\n",
    "        self._source = source\n",
    "        self._balanced_indexes: npt.NDArray[np.int32] | None = None\n",
    "        if balance:\n",
    "            self._balanced_indexes = np.random.shuffle(self._get_balanced_indexes())\n",
    "\n",
    "    def _get_balanced_indexes(self) -> npt.NDArray[np.int32]:\n",
    "        id_train_filepath = os.path.join(self._source, \"id_train.npy\")\n",
    "        id_train: npt.NDArray[np.str_] = np.load(id_train_filepath, allow_pickle=True)\n",
    "        idxAsiago = np.array(\n",
    "            [i for i in range(id_train.shape[0]) if id_train[i][:2] == \"SN\"]\n",
    "        )\n",
    "        idxZTF = np.array(\n",
    "            [i for i in range(id_train.shape[0]) if id_train[i][:3] == \"ZTF\"]\n",
    "        )\n",
    "        nimb = int(idxZTF.shape[0] / idxAsiago.shape[0])\n",
    "\n",
    "        idxbal = np.array([], dtype=int)\n",
    "        for i in range(nimb + 1):\n",
    "            idxbal = np.concatenate([idxbal, idxAsiago])\n",
    "            idxbal = np.concatenate(\n",
    "                [\n",
    "                    idxbal,\n",
    "                    idxZTF[\n",
    "                        i * idxAsiago.shape[0] : min(\n",
    "                            idxZTF.shape[0], (i + 1) * idxAsiago.shape[0]\n",
    "                        )\n",
    "                    ],\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        return idxbal\n",
    "\n",
    "    @property\n",
    "    def X(self) -> npt.NDArray[np.float32]:\n",
    "        x_train_filepath = os.path.join(self._source, \"X_train.npy\")\n",
    "        X_train: npt.NDArray[np.float32] = np.load(x_train_filepath)\n",
    "\n",
    "        if self._balanced_indexes is not None:\n",
    "            X_train = X_train[self._balanced_indexes]\n",
    "\n",
    "        return X_train.swapaxes(3, 1).swapaxes(2, 3)\n",
    "\n",
    "    @property\n",
    "    def y(self) -> npt.NDArray[np.float32]:\n",
    "        y_train_filepath = os.path.join(self._source, \"y_train.npy\")\n",
    "        y_train: npt.NDArray[np.float32] = np.load(y_train_filepath)\n",
    "\n",
    "        if self._balanced_indexes is not None:\n",
    "            y_train = y_train[self._balanced_indexes]\n",
    "\n",
    "        return y_train\n",
    "\n",
    "\n",
    "class ValidationSetProcessor:\n",
    "    def __init__(self, source: str, pixscale_mask_value: float | None = None):\n",
    "        self._source = source\n",
    "        self._pixscale_mask: npt.NDArray[np.int32] | None = None\n",
    "        if pixscale_mask_value is not None:\n",
    "            self._pixscale_mask = self._get_distance_mask(pixscale_mask_value)\n",
    "\n",
    "    def _get_distance_mask(self, pixscale: float) -> npt.NDArray[np.int32]:\n",
    "        y_validation_filepath = os.path.join(self._source, \"y_validation.npy\")\n",
    "        y_validation: npt.NDArray[np.float32] = np.load(y_validation_filepath)\n",
    "\n",
    "        distance = np.sqrt(np.sum(y_validation**2, axis=1))\n",
    "        return (distance * pixscale) < 60\n",
    "\n",
    "    @property\n",
    "    def X(self) -> npt.NDArray[np.float32]:\n",
    "        x_validation_filepath = os.path.join(self._source, \"X_validation.npy\")\n",
    "        X_validation: npt.NDArray[np.float32] = np.load(x_validation_filepath)\n",
    "\n",
    "        if self._pixscale_mask is not None:\n",
    "            X_validation = X_validation[self._pixscale_mask]\n",
    "\n",
    "        return X_validation.swapaxes(3, 1).swapaxes(2, 3)\n",
    "\n",
    "    @property\n",
    "    def y(self) -> npt.NDArray[np.float32]:\n",
    "        y_validation_filepath = os.path.join(self._source, \"y_validation.npy\")\n",
    "        y_validation: npt.NDArray[np.float32] = np.load(y_validation_filepath)\n",
    "\n",
    "        if self._pixscale_mask is not None:\n",
    "            y_validation = y_validation[self._pixscale_mask]\n",
    "\n",
    "        return y_validation\n",
    "\n",
    "\n",
    "class TestingSetProcessor:\n",
    "    def __init__(self, source: str):\n",
    "        self._source = source\n",
    "\n",
    "    @property\n",
    "    def X(self) -> npt.NDArray[np.float32]:\n",
    "        x_test_filepath = os.path.join(self._source, \"X_test.npy\")\n",
    "        x_test: npt.NDArray[np.float32] = np.load(x_test_filepath)\n",
    "        return x_test.swapaxes(3, 1).swapaxes(2, 1)\n",
    "\n",
    "    @property\n",
    "    def y(self) -> npt.NDArray[np.float32]:\n",
    "        y_test_filepath = os.path.join(self._source, \"y_test.npy\")\n",
    "        return np.load(y_test_filepath)\n",
    "\n",
    "\n",
    "class ProductionTrainingSetProcessor:\n",
    "    def __init__(self, source: str):\n",
    "        self._source = source\n",
    "        self._training_set = TrainingSetProcessor(source)\n",
    "        self._validation_set = ValidationSetProcessor(source)\n",
    "\n",
    "    @property\n",
    "    def X(self) -> npt.NDArray[np.float32]:\n",
    "        return np.concatenate((self._training_set.X, self._validation_set.X))\n",
    "\n",
    "    @property\n",
    "    def y(self) -> npt.NDArray[np.float32]:\n",
    "        return np.concatenate((self._training_set.y, self._validation_set.y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset settigns\n",
    "source = os.path.join(os.getcwd(), \"data\")\n",
    "dataset_options = DelightDatasetOptions(channels=1, levels=5, rot=True, flip=True)\n",
    "balance_training_set = True\n",
    "validation_pixscale_mask_value = 0.25\n",
    "\n",
    "# Training settings\n",
    "device: torch.device = torch.device(\"mps\")\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "adam_learning_rate = 0.0014\n",
    "adam_weight_decay = 1e-4\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = partial(\n",
    "    torch.optim.Adam,  # type: ignore\n",
    "    lr=adam_learning_rate,\n",
    "    weight_decay=adam_weight_decay,\n",
    ")\n",
    "\n",
    "train_dataset = DelightDataset(\n",
    "    processor=TrainingSetProcessor(source, balance=balance_training_set),\n",
    "    options=dataset_options,\n",
    ")\n",
    "val_dataset = DelightDataset(\n",
    "    processor=ValidationSetProcessor(\n",
    "        source, pixscale_mask_value=validation_pixscale_mask_value\n",
    "    ),\n",
    "    options=dataset_options,\n",
    ")\n",
    "\n",
    "# We create a `delightcnn.training.TrainingOptions` objects\n",
    "# To separate Hyperparameters (ones where Raytune will create a grid)\n",
    "# From training specifications\n",
    "training_options = TrainingOptions(\n",
    "    criterion=criterion,\n",
    "    dataset_options=dataset_options,\n",
    "    optimizer=optimizer,  # type: ignore\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    epochs=epochs,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining `run_ray_tune`Â function\n",
    "\n",
    "We have to define `run_ray_tune` with hyperparams defines in `delightcnn.training.HyperParameters`\n",
    "\n",
    "This package comes with `ray_wrapper_traning_function`, that is responsable to converts HyperParameters into DelightCnn parameters and uses `TrainingOptions` to create all the required objects to start a training session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ray_tune(\n",
    "    *,\n",
    "    name: str,\n",
    "    num_samples: int,\n",
    "    gpus_per_trial: float,\n",
    "    training_options: TrainingOptions,\n",
    "):\n",
    "    param_space = {\n",
    "        \"nconv1\": tune.lograndint(16, 64 + 1),\n",
    "        \"nconv2\": tune.lograndint(16, 64 + 1),\n",
    "        \"nconv3\": tune.lograndint(16, 64 + 1),\n",
    "        \"ndense\": tune.lograndint(256, 2048 + 1),\n",
    "        \"dropout\": tune.uniform(0, 0.4),\n",
    "        \"batch_size\": tune.lograndint(16, 64 + 1),\n",
    "    }\n",
    "\n",
    "    scheduler = ASHAScheduler(\n",
    "        grace_period=20,  # epochs before evaluate early stop\n",
    "        reduction_factor=3,  # the worst 1/3 trials will be terminated\n",
    "        brackets=1,  # we don't want to decrease resources\n",
    "    )\n",
    "\n",
    "    train_fn = partial(ray_wrapper_training_function, training_options=training_options)\n",
    "\n",
    "    tuner = tune.Tuner(\n",
    "        tune.with_resources(train_fn, resources={\"gpu\": gpus_per_trial}),  # type: ignore\n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=\"val_loss\", mode=\"min\", scheduler=scheduler, num_samples=num_samples\n",
    "        ),\n",
    "        run_config=train.RunConfig(name=name),\n",
    "        param_space=param_space,\n",
    "    )\n",
    "    return tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 00:00:25,344\tWARNING tune.py:219 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now()\n",
    "name = f\"ray_experiment_{now.strftime('%d_%m_%Y-%H_%M_%S')}\"\n",
    "num_samples = 200\n",
    "\n",
    "result = run_ray_tune(\n",
    "    name=name,\n",
    "    num_samples=num_samples,\n",
    "    gpus_per_trial=0.2,\n",
    "    training_options=training_options,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "refactorized-2m7BYJ1-",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
