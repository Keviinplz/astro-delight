{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training DelightCnn Model\n",
    "\n",
    "This notebook shows an example of how to use DelightCnn package to train and use the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from functools import partial\n",
    "\n",
    "import gdown\n",
    "import torch\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "\n",
    "from delightcnn.utils.stoppers import EarlyStopper\n",
    "from delightcnn.model import DelightCnnParameters\n",
    "from delightcnn.dataset import DelightDataset, DelightDatasetOptions\n",
    "from delightcnn.training import execute_train_model\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"[%(asctime)s %(levelname)s]: %(message)s\",\n",
    "    level=logging.INFO,\n",
    "    stream=sys.stderr,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading dataset used in [Delight Paper](https://arxiv.org/pdf/2208.04310)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder contents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 1TQDnl-cmb5rfW3VGKKTwXnTkX6LqVK_c id_train.npy\n",
      "Processing file 1IIqPqScappd8_TLEBY-v0iv4UNPGyFFk id_validation.npy\n",
      "Processing file 1zYShTB3llnZI5DTvsApUyYk4LZR-x_5m X_test.npy\n",
      "Processing file 1BFzBRClUJH9xqtijm3-N3pDzCzdX3q2R X_train.npy\n",
      "Processing file 1VCjSuwFxTgJTOHe4RvbWmqqNJolL0BcV X_validation.npy\n",
      "Processing file 15j0HXm_bPcnR6GuZuG2Jf2gm2CRsjPqK y_test.npy\n",
      "Processing file 1EuJLDgyXH8lbrxi0UjdVku2HOq52P5QQ y_train.npy\n",
      "Processing file 1Zezs_TxyFgaaLUZ57tleFV1h_R3nPl7G y_validation.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder contents completed\n",
      "Building directory structure\n",
      "Building directory structure completed\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1TQDnl-cmb5rfW3VGKKTwXnTkX6LqVK_c\n",
      "To: /Users/keviinplz/thesis/data/id_train.npy\n",
      "100%|██████████| 206k/206k [00:00<00:00, 6.02MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1IIqPqScappd8_TLEBY-v0iv4UNPGyFFk\n",
      "To: /Users/keviinplz/thesis/data/id_validation.npy\n",
      "100%|██████████| 51.3k/51.3k [00:00<00:00, 5.10MB/s]\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1zYShTB3llnZI5DTvsApUyYk4LZR-x_5m\n",
      "From (redirected): https://drive.google.com/uc?id=1zYShTB3llnZI5DTvsApUyYk4LZR-x_5m&confirm=t&uuid=64fd7d71-8213-4790-89c2-1f0a2f44022b\n",
      "To: /Users/keviinplz/thesis/data/X_test.npy\n",
      "100%|██████████| 172M/172M [00:05<00:00, 28.9MB/s] \n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1BFzBRClUJH9xqtijm3-N3pDzCzdX3q2R\n",
      "From (redirected): https://drive.google.com/uc?id=1BFzBRClUJH9xqtijm3-N3pDzCzdX3q2R&confirm=t&uuid=b40bd262-582b-4e6a-83d4-ad2a17345d0e\n",
      "To: /Users/keviinplz/thesis/data/X_train.npy\n",
      "100%|██████████| 346M/346M [00:09<00:00, 34.9MB/s] \n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1VCjSuwFxTgJTOHe4RvbWmqqNJolL0BcV\n",
      "To: /Users/keviinplz/thesis/data/X_validation.npy\n",
      "100%|██████████| 86.5M/86.5M [00:02<00:00, 31.8MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=15j0HXm_bPcnR6GuZuG2Jf2gm2CRsjPqK\n",
      "To: /Users/keviinplz/thesis/data/y_test.npy\n",
      "100%|██████████| 76.7k/76.7k [00:00<00:00, 3.63MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1EuJLDgyXH8lbrxi0UjdVku2HOq52P5QQ\n",
      "To: /Users/keviinplz/thesis/data/y_train.npy\n",
      "100%|██████████| 154k/154k [00:00<00:00, 6.36MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Zezs_TxyFgaaLUZ57tleFV1h_R3nPl7G\n",
      "To: /Users/keviinplz/thesis/data/y_validation.npy\n",
      "100%|██████████| 38.6k/38.6k [00:00<00:00, 2.68MB/s]\n",
      "Download completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/keviinplz/thesis/data/id_train.npy',\n",
       " '/Users/keviinplz/thesis/data/id_validation.npy',\n",
       " '/Users/keviinplz/thesis/data/X_test.npy',\n",
       " '/Users/keviinplz/thesis/data/X_train.npy',\n",
       " '/Users/keviinplz/thesis/data/X_validation.npy',\n",
       " '/Users/keviinplz/thesis/data/y_test.npy',\n",
       " '/Users/keviinplz/thesis/data/y_train.npy',\n",
       " '/Users/keviinplz/thesis/data/y_validation.npy']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://drive.google.com/drive/u/2/folders/1UkHvXq2oNySMN2Hv2K1H9ptygvi2KgdM\"\n",
    "source = os.path.join(os.getcwd(), \"data\")\n",
    "gdown.download_folder(url, output=source, quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processors\n",
    "\n",
    "A processor is an object that defines where and how data has to be retrieved from a given `source`.\n",
    "It has to follow the `delightcnn.dataset.Processor` protocol defining `X` and `y` properties.\n",
    "\n",
    "This approach allows user to be flexible in where and how data has to be processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingSetProcessor:\n",
    "    def __init__(self, source: str, balance: bool = False):\n",
    "        self._source = source\n",
    "        self._balanced_indexes: npt.NDArray[np.int32] | None = None\n",
    "        if balance:\n",
    "            self._balanced_indexes = np.random.shuffle(self._get_balanced_indexes())\n",
    "\n",
    "    def _get_balanced_indexes(self) -> npt.NDArray[np.int32]:\n",
    "        id_train_filepath = os.path.join(self._source, \"id_train.npy\")\n",
    "        id_train: npt.NDArray[np.str_] = np.load(id_train_filepath, allow_pickle=True)\n",
    "        idxAsiago = np.array(\n",
    "            [i for i in range(id_train.shape[0]) if id_train[i][:2] == \"SN\"]\n",
    "        )\n",
    "        idxZTF = np.array(\n",
    "            [i for i in range(id_train.shape[0]) if id_train[i][:3] == \"ZTF\"]\n",
    "        )\n",
    "        nimb = int(idxZTF.shape[0] / idxAsiago.shape[0])\n",
    "\n",
    "        idxbal = np.array([], dtype=int)\n",
    "        for i in range(nimb + 1):\n",
    "            idxbal = np.concatenate([idxbal, idxAsiago])\n",
    "            idxbal = np.concatenate(\n",
    "                [\n",
    "                    idxbal,\n",
    "                    idxZTF[\n",
    "                        i * idxAsiago.shape[0] : min(\n",
    "                            idxZTF.shape[0], (i + 1) * idxAsiago.shape[0]\n",
    "                        )\n",
    "                    ],\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        return idxbal\n",
    "\n",
    "    @property\n",
    "    def X(self) -> npt.NDArray[np.float32]:\n",
    "        x_train_filepath = os.path.join(self._source, \"X_train.npy\")\n",
    "        X_train: npt.NDArray[np.float32] = np.load(x_train_filepath)\n",
    "\n",
    "        if self._balanced_indexes is not None:\n",
    "            X_train = X_train[self._balanced_indexes]\n",
    "\n",
    "        return X_train.swapaxes(3, 1).swapaxes(2, 3)\n",
    "\n",
    "    @property\n",
    "    def y(self) -> npt.NDArray[np.float32]:\n",
    "        y_train_filepath = os.path.join(self._source, \"y_train.npy\")\n",
    "        y_train: npt.NDArray[np.float32] = np.load(y_train_filepath)\n",
    "\n",
    "        if self._balanced_indexes is not None:\n",
    "            y_train = y_train[self._balanced_indexes]\n",
    "\n",
    "        return y_train\n",
    "\n",
    "\n",
    "class ValidationSetProcessor:\n",
    "    def __init__(self, source: str, pixscale_mask_value: float | None = None):\n",
    "        self._source = source\n",
    "        self._pixscale_mask: npt.NDArray[np.int32] | None = None\n",
    "        if pixscale_mask_value is not None:\n",
    "            self._pixscale_mask = self._get_distance_mask(pixscale_mask_value)\n",
    "\n",
    "    def _get_distance_mask(self, pixscale: float) -> npt.NDArray[np.int32]:\n",
    "        y_validation_filepath = os.path.join(self._source, \"y_validation.npy\")\n",
    "        y_validation: npt.NDArray[np.float32] = np.load(y_validation_filepath)\n",
    "\n",
    "        distance = np.sqrt(np.sum(y_validation**2, axis=1))\n",
    "        return (distance * pixscale) < 60\n",
    "\n",
    "    @property\n",
    "    def X(self) -> npt.NDArray[np.float32]:\n",
    "        x_validation_filepath = os.path.join(self._source, \"X_validation.npy\")\n",
    "        X_validation: npt.NDArray[np.float32] = np.load(x_validation_filepath)\n",
    "\n",
    "        if self._pixscale_mask is not None:\n",
    "            X_validation = X_validation[self._pixscale_mask]\n",
    "\n",
    "        return X_validation.swapaxes(3, 1).swapaxes(2, 3)\n",
    "\n",
    "    @property\n",
    "    def y(self) -> npt.NDArray[np.float32]:\n",
    "        y_validation_filepath = os.path.join(self._source, \"y_validation.npy\")\n",
    "        y_validation: npt.NDArray[np.float32] = np.load(y_validation_filepath)\n",
    "\n",
    "        if self._pixscale_mask is not None:\n",
    "            y_validation = y_validation[self._pixscale_mask]\n",
    "\n",
    "        return y_validation\n",
    "\n",
    "\n",
    "class TestingSetProcessor:\n",
    "    def __init__(self, source: str):\n",
    "        self._source = source\n",
    "\n",
    "    @property\n",
    "    def X(self) -> npt.NDArray[np.float32]:\n",
    "        x_test_filepath = os.path.join(self._source, \"X_test.npy\")\n",
    "        x_test: npt.NDArray[np.float32] = np.load(x_test_filepath)\n",
    "        return x_test.swapaxes(3, 1).swapaxes(2, 1)\n",
    "\n",
    "    @property\n",
    "    def y(self) -> npt.NDArray[np.float32]:\n",
    "        y_test_filepath = os.path.join(self._source, \"y_test.npy\")\n",
    "        return np.load(y_test_filepath)\n",
    "\n",
    "\n",
    "class ProductionTrainingSetProcessor:\n",
    "    def __init__(self, source: str):\n",
    "        self._source = source\n",
    "        self._training_set = TrainingSetProcessor(source)\n",
    "        self._validation_set = ValidationSetProcessor(source)\n",
    "\n",
    "    @property\n",
    "    def X(self) -> npt.NDArray[np.float32]:\n",
    "        return np.concatenate((self._training_set.X, self._validation_set.X))\n",
    "\n",
    "    @property\n",
    "    def y(self) -> npt.NDArray[np.float32]:\n",
    "        return np.concatenate((self._training_set.y, self._validation_set.y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "The follows suggests some settings to train a DelightCnn model.\n",
    "\n",
    "It uses `delightcnn.training.execute_train_model` function to train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset settigns\n",
    "source = os.path.join(os.getcwd(), \"data\")\n",
    "dataset_options = DelightDatasetOptions(channels=1, levels=5, rot=True, flip=True)\n",
    "balance_training_set = True\n",
    "validation_pixscale_mask_value = 0.25\n",
    "\n",
    "# Model settings\n",
    "model_parameters = DelightCnnParameters(\n",
    "    nconv1=16,\n",
    "    nconv2=16,\n",
    "    nconv3=32,\n",
    "    ndense=128,\n",
    "    dropout=0.06,\n",
    "    channels=dataset_options.channels,\n",
    "    levels=dataset_options.levels,\n",
    "    rot=dataset_options.rot,\n",
    "    flip=dataset_options.flip,\n",
    ")\n",
    "\n",
    "# Training settings\n",
    "device: torch.device = torch.device(\"mps\")\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "adam_learning_rate = 0.0014\n",
    "adam_weight_decay = 1e-4\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = partial(\n",
    "    torch.optim.Adam,  # type: ignore\n",
    "    lr=adam_learning_rate,\n",
    "    weight_decay=adam_weight_decay,\n",
    ")\n",
    "\n",
    "# You can use other Stopper strategy\n",
    "# Following `delightcnn.utils.stoppers.Stopper` protocol\n",
    "stopper = EarlyStopper(patience=3, min_delta=0)\n",
    "writter = SummaryWriter()\n",
    "\n",
    "train_dataset = DelightDataset(\n",
    "    processor=TrainingSetProcessor(source, balance=balance_training_set),\n",
    "    options=dataset_options,\n",
    ")\n",
    "val_dataset = DelightDataset(\n",
    "    processor=ValidationSetProcessor(\n",
    "        source, pixscale_mask_value=validation_pixscale_mask_value\n",
    "    ),\n",
    "    options=dataset_options,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-10-29 00:23:00,844 INFO]: [EPOCH 1] train loss = 2408.1670989990234 | val_loss = 296.975034383138\n",
      "[2024-10-29 00:23:00,845 INFO]: Validation loss has been improved from inf -> 296.975034383138\n",
      "[2024-10-29 00:23:10,895 INFO]: [EPOCH 2] train loss = 1716.3822231292725 | val_loss = 213.41258761088054\n",
      "[2024-10-29 00:23:10,896 INFO]: Validation loss has been improved from 296.975034383138 -> 213.41258761088054\n",
      "[2024-10-29 00:23:20,803 INFO]: [EPOCH 3] train loss = 1336.0316133499146 | val_loss = 186.77573875427245\n",
      "[2024-10-29 00:23:20,804 INFO]: Validation loss has been improved from 213.41258761088054 -> 186.77573875427245\n",
      "[2024-10-29 00:23:30,832 INFO]: [EPOCH 4] train loss = 1082.6466007232666 | val_loss = 154.44075614929199\n",
      "[2024-10-29 00:23:30,833 INFO]: Validation loss has been improved from 186.77573875427245 -> 154.44075614929199\n",
      "[2024-10-29 00:23:40,934 INFO]: [EPOCH 5] train loss = 914.9907398223877 | val_loss = 152.44388626098632\n",
      "[2024-10-29 00:23:40,935 INFO]: Validation loss has been improved from 154.44075614929199 -> 152.44388626098632\n",
      "[2024-10-29 00:23:51,031 INFO]: [EPOCH 6] train loss = 777.5707845687866 | val_loss = 126.03114799499512\n",
      "[2024-10-29 00:23:51,032 INFO]: Validation loss has been improved from 152.44388626098632 -> 126.03114799499512\n",
      "[2024-10-29 00:24:01,014 INFO]: [EPOCH 7] train loss = 677.1243505477905 | val_loss = 113.85769767761231\n",
      "[2024-10-29 00:24:01,015 INFO]: Validation loss has been improved from 126.03114799499512 -> 113.85769767761231\n",
      "[2024-10-29 00:24:11,290 INFO]: [EPOCH 8] train loss = 595.3789167404175 | val_loss = 106.22863657633464\n",
      "[2024-10-29 00:24:11,290 INFO]: Validation loss has been improved from 113.85769767761231 -> 106.22863657633464\n",
      "[2024-10-29 00:24:21,882 INFO]: [EPOCH 9] train loss = 525.2335262298584 | val_loss = 91.16774522145589\n",
      "[2024-10-29 00:24:21,882 INFO]: Validation loss has been improved from 106.22863657633464 -> 91.16774522145589\n",
      "[2024-10-29 00:24:32,583 INFO]: [EPOCH 10] train loss = 467.6694531440735 | val_loss = 84.48910143534343\n",
      "[2024-10-29 00:24:32,585 INFO]: Validation loss has been improved from 91.16774522145589 -> 84.48910143534343\n"
     ]
    }
   ],
   "source": [
    "model = execute_train_model(\n",
    "    model_parameters=model_parameters,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,  # type: ignore\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    stopper=stopper,\n",
    "    device=device,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "refactorized-2m7BYJ1-",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
