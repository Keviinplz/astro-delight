{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training DelightCnn Model\n",
    "\n",
    "This notebook shows an example of how to use DelightCnn package to train and use the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "\n",
    "from delightcnn.utils.stoppers import EarlyStopper\n",
    "from delightcnn.model import DelightCnnParameters\n",
    "from delightcnn.dataset import DelightDataset, DelightDatasetOptions\n",
    "from delightcnn.training import execute_train_model\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"[%(asctime)s %(levelname)s]: %(message)s\",\n",
    "    level=logging.INFO,\n",
    "    stream=sys.stderr,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processors\n",
    "\n",
    "A processor is an object that defines where and how data has to be retrieved from a given `source`.\n",
    "It has to follow the `delightcnn.dataset.Processor`Â protocol defining `X` and `y` properties.\n",
    "\n",
    "This approach allows user to be flexible in where and how data has to be processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingSetProcessor:\n",
    "    def __init__(self, source: str, balance: bool = False):\n",
    "        self._source = source\n",
    "        self._balanced_indexes: npt.NDArray[np.int32] | None = None\n",
    "        if balance:\n",
    "            self._balanced_indexes = np.random.shuffle(self._get_balanced_indexes())\n",
    "\n",
    "    def _get_balanced_indexes(self) -> npt.NDArray[np.int32]:\n",
    "        id_train_filepath = os.path.join(self._source, \"id_train.npy\")\n",
    "        id_train: npt.NDArray[np.str_] = np.load(id_train_filepath, allow_pickle=True)\n",
    "        idxAsiago = np.array(\n",
    "            [i for i in range(id_train.shape[0]) if id_train[i][:2] == \"SN\"]\n",
    "        )\n",
    "        idxZTF = np.array(\n",
    "            [i for i in range(id_train.shape[0]) if id_train[i][:3] == \"ZTF\"]\n",
    "        )\n",
    "        nimb = int(idxZTF.shape[0] / idxAsiago.shape[0])\n",
    "\n",
    "        idxbal = np.array([], dtype=int)\n",
    "        for i in range(nimb + 1):\n",
    "            idxbal = np.concatenate([idxbal, idxAsiago])\n",
    "            idxbal = np.concatenate(\n",
    "                [\n",
    "                    idxbal,\n",
    "                    idxZTF[\n",
    "                        i * idxAsiago.shape[0] : min(\n",
    "                            idxZTF.shape[0], (i + 1) * idxAsiago.shape[0]\n",
    "                        )\n",
    "                    ],\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        return idxbal\n",
    "\n",
    "    @property\n",
    "    def X(self) -> npt.NDArray[np.float32]:\n",
    "        x_train_filepath = os.path.join(self._source, \"X_train.npy\")\n",
    "        X_train: npt.NDArray[np.float32] = np.load(x_train_filepath)\n",
    "\n",
    "        if self._balanced_indexes is not None:\n",
    "            X_train = X_train[self._balanced_indexes]\n",
    "\n",
    "        return X_train.swapaxes(3, 1).swapaxes(2, 3)\n",
    "\n",
    "    @property\n",
    "    def y(self) -> npt.NDArray[np.float32]:\n",
    "        y_train_filepath = os.path.join(self._source, \"y_train.npy\")\n",
    "        y_train: npt.NDArray[np.float32] = np.load(y_train_filepath)\n",
    "\n",
    "        if self._balanced_indexes is not None:\n",
    "            y_train = y_train[self._balanced_indexes]\n",
    "\n",
    "        return y_train\n",
    "\n",
    "\n",
    "class ValidationSetProcessor:\n",
    "    def __init__(self, source: str, pixscale_mask_value: float | None = None):\n",
    "        self._source = source\n",
    "        self._pixscale_mask: npt.NDArray[np.int32] | None = None\n",
    "        if pixscale_mask_value is not None:\n",
    "            self._pixscale_mask = self._get_distance_mask(pixscale_mask_value)\n",
    "\n",
    "    def _get_distance_mask(self, pixscale: float) -> npt.NDArray[np.int32]:\n",
    "        y_validation_filepath = os.path.join(self._source, \"y_validation.npy\")\n",
    "        y_validation: npt.NDArray[np.float32] = np.load(y_validation_filepath)\n",
    "\n",
    "        distance = np.sqrt(np.sum(y_validation**2, axis=1))\n",
    "        return (distance * pixscale) < 60\n",
    "\n",
    "    @property\n",
    "    def X(self) -> npt.NDArray[np.float32]:\n",
    "        x_validation_filepath = os.path.join(self._source, \"X_validation.npy\")\n",
    "        X_validation: npt.NDArray[np.float32] = np.load(x_validation_filepath)\n",
    "\n",
    "        if self._pixscale_mask is not None:\n",
    "            X_validation = X_validation[self._pixscale_mask]\n",
    "\n",
    "        return X_validation.swapaxes(3, 1).swapaxes(2, 3)\n",
    "\n",
    "    @property\n",
    "    def y(self) -> npt.NDArray[np.float32]:\n",
    "        y_validation_filepath = os.path.join(self._source, \"y_validation.npy\")\n",
    "        y_validation: npt.NDArray[np.float32] = np.load(y_validation_filepath)\n",
    "\n",
    "        if self._pixscale_mask is not None:\n",
    "            y_validation = y_validation[self._pixscale_mask]\n",
    "\n",
    "        return y_validation\n",
    "\n",
    "\n",
    "class TestingSetProcessor:\n",
    "    def __init__(self, source: str):\n",
    "        self._source = source\n",
    "\n",
    "    @property\n",
    "    def X(self) -> npt.NDArray[np.float32]:\n",
    "        x_test_filepath = os.path.join(self._source, \"X_test.npy\")\n",
    "        x_test: npt.NDArray[np.float32] = np.load(x_test_filepath)\n",
    "        return x_test.swapaxes(3, 1).swapaxes(2, 1)\n",
    "\n",
    "    @property\n",
    "    def y(self) -> npt.NDArray[np.float32]:\n",
    "        y_test_filepath = os.path.join(self._source, \"y_test.npy\")\n",
    "        return np.load(y_test_filepath)\n",
    "\n",
    "\n",
    "class ProductionTrainingSetProcessor:\n",
    "    def __init__(self, source: str):\n",
    "        self._source = source\n",
    "        self._training_set = TrainingSetProcessor(source)\n",
    "        self._validation_set = ValidationSetProcessor(source)\n",
    "\n",
    "    @property\n",
    "    def X(self) -> npt.NDArray[np.float32]:\n",
    "        return np.concatenate((self._training_set.X, self._validation_set.X))\n",
    "\n",
    "    @property\n",
    "    def y(self) -> npt.NDArray[np.float32]:\n",
    "        return np.concatenate((self._training_set.y, self._validation_set.y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "The follows suggests some settings to train a DelightCnn model.\n",
    "\n",
    "It uses `delightcnn.training.execute_train_model` function to train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset settigns\n",
    "source = os.path.join(os.getcwd(), \"data\")\n",
    "dataset_options = DelightDatasetOptions(channels=1, levels=5, rot=True, flip=True)\n",
    "balance_training_set = True\n",
    "validation_pixscale_mask_value = 0.25\n",
    "\n",
    "# Model settings\n",
    "model_parameters = DelightCnnParameters(\n",
    "    nconv1=16,\n",
    "    nconv2=16,\n",
    "    nconv3=32,\n",
    "    ndense=128,\n",
    "    dropout=0.06,\n",
    "    channels=dataset_options.channels,\n",
    "    levels=dataset_options.levels,\n",
    "    rot=dataset_options.rot,\n",
    "    flip=dataset_options.flip,\n",
    ")\n",
    "\n",
    "# Training settings\n",
    "device: torch.device = torch.device(\"mps\")\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "adam_learning_rate = 0.0014\n",
    "adam_weight_decay = 1e-4\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = partial(\n",
    "    torch.optim.Adam,  # type: ignore\n",
    "    lr=adam_learning_rate,\n",
    "    weight_decay=adam_weight_decay,\n",
    ")\n",
    "\n",
    "# You can use other Stopper strategy\n",
    "# Following `delightcnn.utils.stoppers.Stopper` protocol\n",
    "stopper = EarlyStopper(patience=3, min_delta=0)\n",
    "writter = SummaryWriter()\n",
    "\n",
    "train_dataset = DelightDataset(\n",
    "    processor=TrainingSetProcessor(source, balance=balance_training_set),\n",
    "    options=dataset_options,\n",
    ")\n",
    "val_dataset = DelightDataset(\n",
    "    processor=ValidationSetProcessor(\n",
    "        source, pixscale_mask_value=validation_pixscale_mask_value\n",
    "    ),\n",
    "    options=dataset_options,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-10-28 23:57:57,776 INFO]: [EPOCH 1] train loss = 2432.1308670043945 | val_loss = 319.6008287556966\n",
      "[2024-10-28 23:57:57,777 INFO]: Validation loss has been improved from inf -> 319.6008287556966\n",
      "[2024-10-28 23:58:07,776 INFO]: [EPOCH 2] train loss = 1732.9202823638916 | val_loss = 231.68574391682944\n",
      "[2024-10-28 23:58:07,776 INFO]: Validation loss has been improved from 319.6008287556966 -> 231.68574391682944\n",
      "[2024-10-28 23:58:17,777 INFO]: [EPOCH 3] train loss = 1355.9878959655762 | val_loss = 175.5977572377523\n",
      "[2024-10-28 23:58:17,778 INFO]: Validation loss has been improved from 231.68574391682944 -> 175.5977572377523\n",
      "[2024-10-28 23:58:27,829 INFO]: [EPOCH 4] train loss = 1100.1099672317505 | val_loss = 150.59913828531901\n",
      "[2024-10-28 23:58:27,829 INFO]: Validation loss has been improved from 175.5977572377523 -> 150.59913828531901\n",
      "[2024-10-28 23:58:37,889 INFO]: [EPOCH 5] train loss = 933.0972690582275 | val_loss = 150.0549941507975\n",
      "[2024-10-28 23:58:37,889 INFO]: Validation loss has been improved from 150.59913828531901 -> 150.0549941507975\n",
      "[2024-10-28 23:58:47,909 INFO]: [EPOCH 6] train loss = 798.9871649742126 | val_loss = 126.56932693481446\n",
      "[2024-10-28 23:58:47,909 INFO]: Validation loss has been improved from 150.0549941507975 -> 126.56932693481446\n",
      "[2024-10-28 23:58:57,947 INFO]: [EPOCH 7] train loss = 686.4615445137024 | val_loss = 111.25426228841145\n",
      "[2024-10-28 23:58:57,947 INFO]: Validation loss has been improved from 126.56932693481446 -> 111.25426228841145\n",
      "[2024-10-28 23:59:08,034 INFO]: [EPOCH 8] train loss = 599.9972875118256 | val_loss = 102.35635739644368\n",
      "[2024-10-28 23:59:08,035 INFO]: Validation loss has been improved from 111.25426228841145 -> 102.35635739644368\n",
      "[2024-10-28 23:59:18,089 INFO]: [EPOCH 9] train loss = 535.1592981815338 | val_loss = 93.65253662109374\n",
      "[2024-10-28 23:59:18,089 INFO]: Validation loss has been improved from 102.35635739644368 -> 93.65253662109374\n",
      "[2024-10-28 23:59:28,182 INFO]: [EPOCH 10] train loss = 478.56157171726227 | val_loss = 94.20180455525716\n",
      "[2024-10-28 23:59:28,183 INFO]: Validation loss is not improving. Best val loss=93.65253662109374\n"
     ]
    }
   ],
   "source": [
    "model = execute_train_model(\n",
    "    model_parameters=model_parameters,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,  # type: ignore\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    stopper=stopper,\n",
    "    device=device,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "refactorized-2m7BYJ1-",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
