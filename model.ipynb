{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm.notebook import tqdm\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "QUANTITY_OF_TEST_CASES = 20\n",
    "LOGGING_LEVEL = logging.NOTSET # logging.DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomFormatter(logging.Formatter):\n",
    "\n",
    "    cyan = \"\\x1b[36;20m\"\n",
    "    blue = \"\\x1b[34;20m\"\n",
    "    grey = \"\\x1b[38;20m\"\n",
    "    yellow = \"\\x1b[33;20m\"\n",
    "    red = \"\\x1b[31;20m\"\n",
    "    bold_red = \"\\x1b[31;1m\"\n",
    "    reset = \"\\x1b[0m\"\n",
    "    format = \"[%(asctime)s - %(levelname)s]: %(message)s (%(filename)s:%(lineno)d)\"\n",
    "\n",
    "    FORMATS = {\n",
    "        logging.DEBUG: cyan + format + reset,\n",
    "        logging.INFO: blue + format + reset,\n",
    "        logging.WARNING: yellow + format + reset,\n",
    "        logging.ERROR: red + format + reset,\n",
    "        logging.CRITICAL: bold_red + format + reset\n",
    "    }\n",
    "\n",
    "    def format(self, record):\n",
    "        log_fmt = self.FORMATS.get(record.levelno)\n",
    "        formatter = logging.Formatter(log_fmt)\n",
    "        return formatter.format(record)\n",
    "\n",
    "logger = logging.getLogger(\"notebook\")\n",
    "logger.setLevel(LOGGING_LEVEL)\n",
    "\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(LOGGING_LEVEL)\n",
    "ch.setFormatter(CustomFormatter())\n",
    "logger.addHandler(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_to_string(params: dict) -> str:\n",
    "    name = \"\"\n",
    "    for key, value in params.items():\n",
    "        name += f\"{key}_{value}-\"\n",
    "    return name[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RotationAndFlipLayer(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A layer that converts a (B, L, C, W, H) into a (B * 8 * L, C, W, H)\n",
    "    \"\"\"\n",
    "    def __init__(self, rot: bool = True):\n",
    "        super().__init__()\n",
    "        self.metadata = None\n",
    "        self.rot = rot\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        batch, levels, channels, width, height = x.shape\n",
    "        self.metadata = { \"batch\": batch, \"levels\": levels, \"transforms\": 8 }\n",
    "        \n",
    "        if not self.rot:\n",
    "            transforms = (\n",
    "                x,\n",
    "                x,\n",
    "                x,\n",
    "                x,\n",
    "                x, \n",
    "                x,\n",
    "                x,\n",
    "                x,\n",
    "            )\n",
    "        else:\n",
    "            width_dim = len(x.shape) - 2\n",
    "            height_dim = len(x.shape) - 1\n",
    "            \n",
    "            flipped: torch.Tensor = x.flip(dims=(height_dim,))\n",
    "            flipped_rot90: torch.Tensor = flipped.rot90(k=1, dims=(width_dim, height_dim))\n",
    "            flipped_rot180: torch.Tensor = flipped.rot90(k=2, dims=(width_dim, height_dim))\n",
    "            flipped_rot270: torch.Tensor = flipped.rot90(k=3, dims=(width_dim, height_dim))\n",
    "            rot90: torch.Tensor = x.rot90(k=1, dims=(width_dim, height_dim))\n",
    "            rot180: torch.Tensor = x.rot90(k=2, dims=(width_dim, height_dim))\n",
    "            rot270: torch.tensor = x.rot90(k=3, dims=(width_dim, height_dim))\n",
    "    \n",
    "            transforms = (\n",
    "                x,\n",
    "                rot90,\n",
    "                rot180,\n",
    "                rot270,\n",
    "                flipped, \n",
    "                flipped_rot90,\n",
    "                flipped_rot180,\n",
    "                flipped_rot270,\n",
    "            )\n",
    "\n",
    "        x = torch.cat(transforms, dim=1)\n",
    "        x = x.reshape(batch * levels * len(transforms), channels, width, height)\n",
    "\n",
    "        self.metadata = { \"batch\": batch, \"levels\": levels, \"transforms\": 8 }\n",
    "        return x\n",
    "\n",
    "def test_rotation_and_flip_layer():\n",
    "    layer = RotationAndFlipLayer()\n",
    "    \n",
    "    for _ in range(QUANTITY_OF_TEST_CASES):\n",
    "        batch = random.randint(1, 100)\n",
    "        levels = random.randint(1, 100)\n",
    "\n",
    "        x = torch.zeros((batch, levels, 1, 30, 30))\n",
    "        out = layer.forward(x)\n",
    "\n",
    "        transforms = layer.metadata[\"transforms\"]\n",
    "\n",
    "        expected = batch * levels * 8\n",
    "        assert out.shape == torch.Size([expected, 1, 30, 30]), f\"Test failed with batch {batch} and level {levels}\"\n",
    "\n",
    "        del x\n",
    "        del out\n",
    "\n",
    "    del layer\n",
    "\n",
    "test_rotation_and_flip_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageVisualizer:\n",
    "    def __init__(self):\n",
    "        self._samples_array: list[tensor.Tensor] = []\n",
    "        self._levels = 5\n",
    "\n",
    "    @property\n",
    "    def nsamples(self) -> int:\n",
    "        return len(self._samples_array)\n",
    "    \n",
    "    def plot(self) -> None:\n",
    "        fig = plt.figure(figsize=(14., 14.))\n",
    "        grid = ImageGrid(fig, 111, nrows_ncols=(int(self.nsamples / self._levels), self._levels), axes_pad=0.2)\n",
    "        for ax, im in zip(grid, self._samples_array):\n",
    "            ax.imshow(im)\n",
    "\n",
    "        for level in range(1, self._levels + 1):\n",
    "            grid.axes_all[level - 1].set_title(f\"Level {level}\")\n",
    "        plt.show()\n",
    "        \n",
    "    def add(self, images: torch.Tensor) -> None:\n",
    "        if len(images.shape) != 4:\n",
    "            logger.error(\"Expected 4D tensor: (levels, channels, width, height), received: %s\", images.shape)\n",
    "            raise ValueError(f\"Expected 4D tensor: (levels, channels, width, height), recieved: {images.shape}\")\n",
    "\n",
    "        if images.shape[0] != self._levels:\n",
    "            logger.error(\"Expected 5 levels, received:  %s\", images.shape[0])\n",
    "            raise ValueError(f\"Expected 5 levels, received: {images.shape[0]}\")\n",
    "        \n",
    "        self._samples_array.extend([im.squeeze().numpy().copy() for im in images.chunk(self._levels)])\n",
    "\n",
    "    def clean(self) -> None:\n",
    "        self._samples_array = []\n",
    "\n",
    "def test_image_visualizer():\n",
    "    t1 = torch.rand(5, 1, 30, 30)\n",
    "    t2 = t1.flip(dims=(2,))\n",
    "    t3 = t1.rot90(dims=(2, 3))\n",
    "\n",
    "    visualizer = ImageVisualizer()\n",
    "    visualizer.add(t1)\n",
    "    visualizer.add(t2)\n",
    "    visualizer.add(t3)\n",
    "    \n",
    "    assert visualizer.nsamples == 15\n",
    "\n",
    "    del visualizer\n",
    "    del t3\n",
    "    del t2\n",
    "    del t1\n",
    "\n",
    "test_image_visualizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DELIGHTModel(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    DELIGHT implementation written in torch.\n",
    "\n",
    "    Allows inputs of ([B]atch, [L]evel, 1, 30, 30).\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 rot: bool = True,\n",
    "                 levels: int = 5, \n",
    "                 nconv1: int = 52, \n",
    "                 nconv2: int = 57, \n",
    "                 nconv3: int = 41, \n",
    "                 ndense: int = 685\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.LEVELS = levels\n",
    "        self.CONV2D_ONE_OUT_CHANNELS = nconv1\n",
    "        self.CONV2D_TWO_OUT_CHANNELS = nconv2\n",
    "        self.CONV2D_THREE_OUT_CHANNELS = nconv3\n",
    "        self.LINEAR_TWO_IN = ndense\n",
    "\n",
    "        h = w = 30\n",
    "        conv_kernel_size = 3\n",
    "        mp_kernel_size = 2\n",
    "\n",
    "        self.rot_and_flip = RotationAndFlipLayer(rot=rot)\n",
    "        self.conv1 = torch.nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=self.CONV2D_ONE_OUT_CHANNELS, \n",
    "            kernel_size=conv_kernel_size\n",
    "        )\n",
    "        \n",
    "        self.conv2 = torch.nn.Conv2d(\n",
    "            in_channels=self.conv1.out_channels, \n",
    "            out_channels=self.CONV2D_TWO_OUT_CHANNELS,\n",
    "            kernel_size=conv_kernel_size\n",
    "        )\n",
    "        \n",
    "        self.conv3 = torch.nn.Conv2d(\n",
    "            in_channels=self.conv2.out_channels, \n",
    "            out_channels=self.CONV2D_THREE_OUT_CHANNELS, \n",
    "            kernel_size=conv_kernel_size\n",
    "        )\n",
    "        \n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.max_pool = torch.nn.MaxPool2d(kernel_size=mp_kernel_size)\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        \n",
    "        self.bottleneck = torch.nn.Sequential(\n",
    "            self.conv1,\n",
    "            self.relu,\n",
    "            self.max_pool, \n",
    "            self.conv2,\n",
    "            self.relu,\n",
    "            self.max_pool,\n",
    "            self.conv3,\n",
    "            self.relu,\n",
    "            self.flatten,\n",
    "        )\n",
    "\n",
    "        linear_in = self._compute_fc1_features(\n",
    "            width=w,\n",
    "            height=h,\n",
    "            conv_kernel_size=conv_kernel_size,\n",
    "            mp_kernel_size=mp_kernel_size\n",
    "        )\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(in_features=linear_in, out_features=self.LINEAR_TWO_IN)\n",
    "        self.fc2 = torch.nn.Linear(in_features=self.LINEAR_TWO_IN, out_features=2)\n",
    "        self.tanh = torch.nn.Tanh()\n",
    "\n",
    "    def _compute_fc1_features(self, *, width: int, height: int, conv_kernel_size: int, mp_kernel_size: int) -> int:\n",
    "        height = height - conv_kernel_size + 1          # conv2d 1 \n",
    "        height = math.floor((height - mp_kernel_size)/2 + 1)  # maxpool2d 1 \n",
    "        height = height - conv_kernel_size + 1          # conv2d 2\n",
    "        height = math.floor((height - mp_kernel_size)/2 + 1)  # maxpool2d 2\n",
    "        height = height - conv_kernel_size + 1          # conv2d 3\n",
    "\n",
    "        width = width - conv_kernel_size + 1          # conv2d 1\n",
    "        width = math.floor((width - mp_kernel_size)/2 + 1)  # maxpool2d 1\n",
    "        width = width - conv_kernel_size + 1          # conv2d 2\n",
    "        width = math.floor((width - mp_kernel_size)/2 + 1)  # maxpool2d 2\n",
    "        width = width - conv_kernel_size + 1          # conv2d 3\n",
    "        return height * width * self.CONV2D_THREE_OUT_CHANNELS * self.LEVELS\n",
    "                \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:                \n",
    "        # Apply flips and rotations over level (L) dimension\n",
    "        logger.debug(\"Received input x with shape %s\", x.shape)\n",
    "        x = self.rot_and_flip(x)\n",
    "        batch_size = self.rot_and_flip.metadata[\"batch\"]\n",
    "        n_transforms = self.rot_and_flip.metadata[\"transforms\"]\n",
    "        logger.debug(\"Input was transformed into %s rotations and flip, ended with shape %s\", n_transforms, x.shape) \n",
    "        \n",
    "        # Bottleneck\n",
    "        x = self.bottleneck(x)\n",
    "        logger.debug(\"Input shape after bottleneck: %s\", x.shape)\n",
    "        \n",
    "        # Undo transformations\n",
    "        x = x.reshape(batch_size, n_transforms, -1)\n",
    "        logger.debug(\"Input shape after reshape: %s\", x.shape)\n",
    "        \n",
    "        # Linear\n",
    "        x = self.fc1(x)\n",
    "        logger.debug(\"Input shape after first fully-connected layer: %s\", x.shape)\n",
    "        x = self.tanh(x)\n",
    "        x = self.fc2(x)\n",
    "        logger.debug(\"Input shape after last fully-connected layer: %s\", x.shape)\n",
    "        x = x.reshape((batch_size, n_transforms * 2))\n",
    "        logger.debug(\"Output shape: %s\", x.shape)\n",
    "        \n",
    "        return x\n",
    "def test_input_output_parameters_on_delight_model():\n",
    "    for _ in range(QUANTITY_OF_TEST_CASES):\n",
    "        batch = random.randint(1, 32)\n",
    "        levels = random.randint(1, 5)\n",
    "\n",
    "        x = torch.zeros((batch, levels, 1, 30, 30))\n",
    "        model = DELIGHTModel(levels=levels)\n",
    "\n",
    "        try:\n",
    "            out = model.forward(x)\n",
    "        except RuntimeError:\n",
    "            logger.error(\"Runtime error on model with batch %s and levels %s\", batch, levels)\n",
    "            assert False, f\"Runtime error on model with batch {batch} and levels {levels}\"\n",
    "        \n",
    "        expected = torch.Size([batch, 16])\n",
    "        assert out.shape == expected, f\"Failed with batch {batch} and levels {levels} => {out.shape} != {expected}\"\n",
    "        del out\n",
    "        del model\n",
    "        del x\n",
    "\n",
    "test_input_output_parameters_on_delight_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from enum import Enum\n",
    "from typing import Union\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDatasetType(Enum):\n",
    "    TRAIN = \"TRAIN\"\n",
    "    TEST = \"TEST\"\n",
    "    VALIDATION = \"VALIDATION\"\n",
    "    \n",
    "@dataclass\n",
    "class CustomDatasetOptions:\n",
    "    dataset_type: CustomDatasetType\n",
    "    n_levels: int\n",
    "    fold: int\n",
    "    mask: bool\n",
    "    object: bool\n",
    "\n",
    "    def get_filenames(self) -> str:\n",
    "        if self.dataset_type == CustomDatasetType.TRAIN:\n",
    "            X = \"X_train_nlevels%i_fold%i_mask%s_objects%s.npy\" % (self.n_levels, self.fold, self.mask, self.object)\n",
    "            y = \"y_train_nlevels%i_fold%i_mask%s_objects%s.npy\" % (self.n_levels, self.fold, self.mask, self.object)\n",
    "        elif self.dataset_type == CustomDatasetType.TEST:\n",
    "            X = \"X_test_nlevels%i_mask%s_objects%s.npy\" % (self.n_levels, self.mask, self.object)\n",
    "            y = \"y_test_nlevels%i_mask%s_objects%s.npy\" % (self.n_levels, self.mask, self.object)\n",
    "        else:\n",
    "            X = \"X_val_nlevels%i_fold%i_mask%s_objects%s.npy\" % (self.n_levels, self.fold, self.mask, self.object)\n",
    "            y = \"y_val_nlevels%i_fold%i_mask%s_objects%s.npy\" % (self.n_levels, self.fold, self.mask, self.object)\n",
    "            \n",
    "        return X, y\n",
    "            \n",
    "class CustomDataset(Dataset):    \n",
    "    def __init__(self, options: CustomDatasetOptions, source: Union[str, None] = None, rot: bool = True):\n",
    "        self.source = source if source is not None else \"/home/fforster/SNHosts/data\"\n",
    "        X_path, y_path = options.get_filenames()\n",
    "        self.X = torch.Tensor(np.load(os.path.join(self.source, X_path))).permute(0, 3, 1, 2)\n",
    "        self.y = torch.Tensor(self.rotateY(np.load(os.path.join(self.source, y_path)), rot))\n",
    "\n",
    "    def rotateY(self, y: np.ndarray, rot: bool) -> np.ndarray:\n",
    "        if not rot:\n",
    "            return np.concatenate([\n",
    "                y,\n",
    "                y,\n",
    "                y,\n",
    "                y,\n",
    "                y,\n",
    "                y,\n",
    "                y,\n",
    "                y\n",
    "            ], axis=1)\n",
    "            \n",
    "        y90 = [-1, 1] * y[:, ::-1]\n",
    "        y180 = [-1, 1] * y90[:, ::-1]\n",
    "        y270 = [-1, 1] * y180[:, ::-1]\n",
    "        yflip = [1, -1] * y\n",
    "        yflip90 = [-1, 1] * yflip[:, ::-1]\n",
    "        yflip180 = [-1, 1] * yflip90[:, ::-1]\n",
    "        yflip270 = [-1, 1] * yflip180[:, ::-1]\n",
    "\n",
    "        return np.concatenate([\n",
    "            y,\n",
    "            y90,\n",
    "            y180,\n",
    "            y270,\n",
    "            yflip,\n",
    "            yflip90,\n",
    "            yflip180,\n",
    "            yflip270\n",
    "        ], axis=1)\n",
    "\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        X = self.X[idx]\n",
    "        y = self.y[idx]\n",
    "\n",
    "        if len(X.shape) == 3: # has no channel information\n",
    "            levels, width, height = X.shape \n",
    "            X = X.reshape(levels, 1, width, height) # asume 1 channel information\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_opt = CustomDatasetOptions(\n",
    "    dataset_type=CustomDatasetType.TRAIN,\n",
    "    n_levels=5,\n",
    "    fold=0,\n",
    "    mask=False,\n",
    "    object=True\n",
    ")\n",
    "test_opt = CustomDatasetOptions(\n",
    "    dataset_type=CustomDatasetType.TEST,\n",
    "    n_levels=5,\n",
    "    fold=0,\n",
    "    mask=False,\n",
    "    object=True\n",
    ")\n",
    "val_opt = CustomDatasetOptions(\n",
    "    dataset_type=CustomDatasetType.VALIDATION,\n",
    "    n_levels=5,\n",
    "    fold=0,\n",
    "    mask=False,\n",
    "    object=True\n",
    ")\n",
    "\n",
    "batch_size = 32\n",
    "source = \"/home/keviinplz/universidad/tesis/snhost/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "params = {\n",
    "    \"rot\": True,\n",
    "    \"levels\": 5,\n",
    "    \"nconv1\": 16,\n",
    "    \"nconv2\": 32,\n",
    "    \"nconv3\": 32,\n",
    "    \"ndense\": 128\n",
    "}\n",
    "\n",
    "train = CustomDataset(options=train_opt, source=source, rot=params[\"rot\"])\n",
    "test = CustomDataset(options=test_opt, source=source, rot=params[\"rot\"])\n",
    "val = CustomDataset(options=val_opt, source=source, rot=params[\"rot\"])\n",
    "train_dl = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test_dl = DataLoader(test, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(val, batch_size=batch_size, shuffle=True)\n",
    "model = DELIGHTModel(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "ts = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), weight_decay=1e-4)\n",
    "\n",
    "name = params_to_string(params)\n",
    "writer = SummaryWriter('runs/delight_{}_{}'.format(name, ts))\n",
    "\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch: int, tb_writer: SummaryWriter, device: str = \"cuda\"):\n",
    "        running_loss = 0.\n",
    "        last_loss = 0.\n",
    "    \n",
    "        # Here, we use enumerate(training_loader) instead of\n",
    "        # iter(training_loader) so that we can track the batch\n",
    "        # index and do some intra-epoch reporting\n",
    "        pbar = tqdm(train_dl, leave=False, position=1)\n",
    "        for i, data in enumerate(pbar):\n",
    "            # Every data instance is an input + label pair\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "    \n",
    "            # Zero your gradients for every batch!\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            # Make predictions for this batch\n",
    "            outputs = model(inputs)\n",
    "    \n",
    "            # Compute the loss and its gradients\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "    \n",
    "            # Adjust learning weights\n",
    "            optimizer.step()\n",
    "    \n",
    "            # Gather data and report\n",
    "            running_loss += loss.item()\n",
    "            if i % batch_size == batch_size - 1:\n",
    "                last_loss = running_loss / batch_size # loss per batch\n",
    "                pbar.set_description('batch {} loss: {}'.format(i + 1, last_loss))\n",
    "                tb_x = epoch * len(train_dl) + i + 1\n",
    "                tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "                running_loss = 0.\n",
    "    \n",
    "        return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 87298), started 2:37:18 ago. (Use '!kill 87298' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-27ff3fce2d1ab254\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-27ff3fce2d1ab254\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a52006280e0458d8246a632df7a3031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d929dd3208ed46b6aaf65c1d2d9eb869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b34b482f353414fa463e4ed8fce9336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "054de6edc17f4d939f750ec7cd2dd574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "707c84cdb1e4430b8d09ea2957f0c84b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d8e8745663945afa94e0ed704e7bb6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98d19cbdd9f5427f8f42d7676d8acfbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a7a3ab22af4083960e1e8cf46918fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "120aff4287f3467b9decafadb798d1fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8af4eb2ddf1433aa6c24930d52ff376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4e082d0b7654fbaa0e7fe006b0dfa15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b311c1acacb246f18809d71354b2fdc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b58d4c2231624815852b29025f8f359c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dde8cecf181c468aa6a56de07d0d85d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe0220890e6945f4b373959bb08f111c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae490887e2d6433388ddfd5d7d0ab373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a060a6ecb24faab0b280e5b55b0ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6385d6a2cad644488221b52ebd020615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc467a89c544ce68266455efa36d39d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a9d4cf0faa34a2ba7cd377c98cd6591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecb4403575144e899f4431c06041e404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b0340061a4c4c30b9288e5737d853df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e548f2bb62f465e96b38c3b15a52e5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79ee442c1aa24d5aaffa16be55635365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f864cb9aa6564819bfc917f38a24205c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a08ad8b689914bb5a16ac2082f8e9f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5f6ee29514542bb8f36f61249541531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d70951b5fc864b69a60d815b4e278dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70e2ca23c0be429d8a5106d18f3e3771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985b381448c5463cbeccb1b8735a92c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf1f74c3f6184c7c89c4cadcc6b7f9a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92458bb61aa74be988ccdb3298df3ec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13bee185b63c4e479af0f2e8e2fc9577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f9fe542eff145cba6e2986ad9a4a557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f75709f7fd44e9cbe734e0ad557c8f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02ead65c4d45437696578d4a3f824971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c632662aaf54cd598bb17d1c8c7b36e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "017e1b449c5b4ba39e3c8a88619bc995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "049cdb8fc79f4c33ae87aeb8f9177d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ff424d9d95842e48169adcf4ae33cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffde3a597d71432283fe644c8047d65a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e6003ad91147bcbd9cea2559697c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "633f0c12ecfd45de9d11166b3b352c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a12d5a9d65944b228223738eb48638e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa4b20bbe7c4466aa936cfc213bb96c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d58d6a3d607044bc9f9918a25c71e43c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db491e14cd2b4a659591b96ce17763a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2a00c4b6d5d460597d49f3798d71bfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61b6e127d543408b8c570e6c66bfc303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8943edd9e06a45dfb7b7508cf141b615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85d62d8017f241bfa78c4cda1882f445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/301 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir runs\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "device = \"cuda\"\n",
    "\n",
    "os.makedirs(\"states\", exist_ok=True)\n",
    "\n",
    "pbar = tqdm(range(EPOCHS), leave=False, position=0)\n",
    "\n",
    "for epoch in pbar:\n",
    "    pbar.set_description(\"Running epoch %s\" % epoch)\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    model.to(device)\n",
    "    avg_loss = train_one_epoch(epoch, writer, device)\n",
    "\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(val_dl):\n",
    "            vinputs, vlabels = vdata\n",
    "            vinputs = vinputs.to(device)\n",
    "            vlabels = vlabels.to(device)\n",
    "            \n",
    "            voutputs = model(vinputs)\n",
    "\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    pbar.set_description(\"LOSS train %s valid %s\" % (avg_loss, avg_vloss), refresh=False)\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'states/model_{}_{}'.format(ts, epoch)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(51.7013, device='cuda:0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_vloss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
